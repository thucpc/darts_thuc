{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0d7a7465-fbfc-4a47-9351-ee4f2c6d7fb6","_uuid":"dabfc901-af8f-4146-9d81-1fd2a215283b","collapsed":false,"execution":{"iopub.execute_input":"2024-06-06T09:39:12.385868Z","iopub.status.busy":"2024-06-06T09:39:12.385504Z","iopub.status.idle":"2024-06-06T09:40:48.979592Z","shell.execute_reply":"2024-06-06T09:40:48.978335Z","shell.execute_reply.started":"2024-06-06T09:39:12.385839Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["# try:\n","#     from darts import TimeSeries\n","#     import ipdb\n","# except:\n","# #     !pip install -q darts\n","# #     !pip install --upgrade pip\n","#     !pip install -q git+https://github.com/thucpc/darts_thuc.git\n","#     !pip install -q ipdb\n","#     !pip install -q lightning\n","#     %pip install --upgrade pyarrow\n","# #     !pip install -q optuna-integration\n","# import importlib\n","# if importlib.util.find_spec(\"ipywidgets\") is not None:\n","#     !pip uninstall -y ipywidgets"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e145683a-1812-4603-9462-d284c97bee38","_uuid":"f8e33fb4-de36-44c4-834b-28ba93f49257","execution":{"iopub.execute_input":"2024-06-06T09:42:09.791038Z","iopub.status.busy":"2024-06-06T09:42:09.790673Z","iopub.status.idle":"2024-06-06T09:42:21.126205Z","shell.execute_reply":"2024-06-06T09:42:21.125458Z","shell.execute_reply.started":"2024-06-06T09:42:09.791009Z"},"trusted":true},"outputs":[],"source":["import os\n","import ipdb\n","import glob\n","import pandas as pd\n","import numpy as np\n","import torch\n","import matplotlib.pyplot as plt\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torchmetrics\n","\n","from darts import TimeSeries, concatenate\n","from darts.utils.callbacks import TFMProgressBar\n","\n","# from darts.models.components.glu_variants import SwiGLU\n","from darts.models import TiDEModel,TransformerModel,TFTModel\n","from darts.models.forecasting.transformer_invert import iTransformerModel\n","from darts.metrics import mape, smape, mae\n","from darts.dataprocessing.transformers import Scaler,StaticCovariatesTransformer\n","from darts.utils.timeseries_generation import datetime_attribute_timeseries\n","\n","import logging\n","\n","logging.disable(logging.CRITICAL)\n","\n","import warnings\n","\n","warnings.filterwarnings(\"ignore\")\n","\n","%matplotlib inline\n","\n","# for reproducibility\n","torch.manual_seed(1)\n","np.random.seed(1)\n","pd.set_option('display.max_columns', None)"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"fa3c6e16-0144-405a-83ef-768e5ef8a3f8","_uuid":"6becd8bc-9f1d-49d9-9bb9-830ad7a4cb38","execution":{"iopub.execute_input":"2024-06-06T09:42:23.641544Z","iopub.status.busy":"2024-06-06T09:42:23.641284Z","iopub.status.idle":"2024-06-06T09:42:23.656378Z","shell.execute_reply":"2024-06-06T09:42:23.655402Z","shell.execute_reply.started":"2024-06-06T09:42:23.641514Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","\n","class SwiGLU(nn.Module):\n","    def __init__(self, input_dim=None, d_model=None, beta=1.0):\n","        super().__init__()\n","        self.input_dim = input_dim\n","        if self.input_dim is not None:\n","            self.linear1 = nn.Linear(self.input_dim, self.input_dim)\n","            self.linear2 = nn.Linear(self.input_dim, self.input_dim)\n","        else:\n","            self.linear1 = None\n","            self.linear2 = None\n","        self.beta = nn.Parameter(torch.tensor(beta))  # Biến beta thành tham số có thể học\n","\n","    def forward(self, x):\n","        if self.linear1 is None or self.linear2 is None:\n","            self.linear1 = nn.Linear(x.size(-1), x.size(-1))\n","            self.linear2 = nn.Linear(x.size(-1), x.size(-1))\n","        return self.swish(self.linear1(x)) * self.linear2(x)\n","\n","    def swish(self, x):\n","        return x * torch.sigmoid(self.beta * x)\n","\n","class LogCoshLoss(torch.nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","    def forward(self, y_t, y_prime_t):\n","        ey_t = y_t - y_prime_t\n","        return torch.mean(torch.log(torch.cosh(ey_t + 1e-12)))\n","    \n","class CustomLoss(torch.nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","    def forward(self, input_value, target_value):\n","        error = target_value - input_value\n","        A=torch.sum((target_value**2)*(error**2))\n","        B=torch.sum(target_value**2)\n","        loss = A/B\n","        return loss\n","\n","class CustomLoss1(torch.nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","    def forward(self, input_value, target_value):\n","        error = target_value - input_value\n","        loss = torch.sum(target_value*(error**2))/torch.sum(target_value)\n","        return loss\n","\n","class CustomLoss2(torch.nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","    def forward(self, y_t, y_prime_t):\n","        ey_t = y_t - y_prime_t\n","        loss=torch.sum(y_prime_t**2*torch.log(torch.cosh(ey_t**2 + 1e-12)))\n","        return loss/torch.sum(y_prime_t**2)"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"dffedbf3-fcad-48c7-af06-ec681629ea33","_uuid":"b1876267-2113-480b-9b75-4ff860cd8869","collapsed":false,"execution":{"iopub.execute_input":"2024-06-06T09:42:30.226738Z","iopub.status.busy":"2024-06-06T09:42:30.226435Z","iopub.status.idle":"2024-06-06T09:42:30.239019Z","shell.execute_reply":"2024-06-06T09:42:30.238101Z","shell.execute_reply.started":"2024-06-06T09:42:30.226706Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["list_y=['THUONG_PHAM_D1M']\n","list_lag=['SO_LUONG_KH','SO_LUONG_KH_DMTMN','SAN_LUONG_DMTMN','CONG_SUAT_DMTMN']\n","list_weather=['precip s4', 'precip s3', 'precip 8', 'precip 4', 'precip 2', 'precip 1', 'Average of precip', 'Sum of precip', 'Average of temp', 'Sum of temp', 'Min of tempmin', 'Max of tempmax', 'Sum of tempmax', 'Average of dew', 'Average of humidity', 'Average of pressure', 'Average of windspeed', 'Average of solarradiation', 'Average of solarenergy']\n","list_lag2=['SL1110', 'SL1120', 'SL1200', 'SL1300', 'SL1400', 'SL2100', 'SL2101', 'SL2102', 'SL2103', 'SL2104', 'SL2105', 'SL2201', 'SL2202', 'SL2203', 'SL2204', 'SL2205', 'SL2206', 'SL2207', 'SL2208', 'SL2209', 'SL2210', 'SL2211', 'SL2212', 'SL2213', 'SL2214', 'SL2215', 'SL2216', 'SL2217', 'SL2218', 'SL2219', 'SL2221', 'SL2222', 'SL2223', 'SL2301', 'SL2302', 'SL2303', 'SL2400', 'SL2410', 'SL2420', 'SL2430', 'SL2500', 'SL3100', 'SL3101', 'SL3102', 'SL3200', 'SL3210', 'SL3220', 'SL3230', 'SL4100', 'SL4300', 'SL4400', 'SL4401', 'SL4402', 'SL5000', 'SL5100', 'SL5101', 'SL5102', 'SL5103', 'SL5104', 'SL5200', 'SL5301', 'SL5302', 'SL5400', 'SL5401', 'SL5402', 'SL5403', 'SL5404', 'SL5500', 'KH1110', 'KH1120', 'KH1200', 'KH1300', 'KH1400', 'KH2100', 'KH2101', 'KH2102', 'KH2103', 'KH2104', 'KH2105', 'KH2201', 'KH2202', 'KH2203', 'KH2204', 'KH2205', 'KH2206', 'KH2207', 'KH2208', 'KH2209', 'KH2210', 'KH2211', 'KH2212', 'KH2213', 'KH2214', 'KH2215', 'KH2216', 'KH2217', 'KH2218', 'KH2219', 'KH2221', 'KH2222', 'KH2223', 'KH2301', 'KH2302', 'KH2303', 'KH2400', 'KH2410', 'KH2420', 'KH2430', 'KH2500', 'KH3100', 'KH3101', 'KH3102', 'KH3200', 'KH3210', 'KH3220', 'KH3230', 'KH4100', 'KH4300', 'KH4400', 'KH4401', 'KH4402', 'KH5000', 'KH5100', 'KH5101', 'KH5102', 'KH5103', 'KH5104', 'KH5200', 'KH5301', 'KH5302', 'KH5400', 'KH5401', 'KH5402', 'KH5403', 'KH5404', 'KH5500', '1. Cà phê-Diện tích đang trồng-cao', '1. Cà phê-Giá-cao', '1. Cà phê-Giá-thấp', '2. Tiêu-Diện tích đang trồng-cao', '2. Tiêu-Giá-cao', '2. Tiêu-Giá-thấp', '3. Điều-Diện tích đang trồng-cao', '3. Điều-Giá-cao', '3. Điều-Giá-thấp', '4. Sầu riêng-Diện tích đang trồng-cao', '4. Sầu riêng-Giá-cao', '4. Sầu riêng-Giá-thấp', '5. Cao su-Diện tích đang trồng-cao', '5. Cao su-Giá-cao', '5. Cao su-Giá-thấp', '6. Khoai mì-Diện tích đang trồng-cao', '6. Khoai mì-Giá-cao', '6. Khoai mì-Giá-thấp', '6. Khoai mì-Mã điểm đo trạm bơm-cao', '6. Khoai mì-Thời điểm-Bắt đầu trồng', '6. Khoai mì-Thời điểm-Thu hoạch', '7. Lúa-Diện tích đang trồng-cao', '7. Lúa-Giá-cao', '7. Lúa-Giá-thấp', '7. Lúa-Mã điểm đo trạm bơm-cao', '7. Lúa-Thời điểm-Bắt đầu trồng', '7. Lúa-Thời điểm-Thu hoạch', '8. Heo-Giá-cao', '8. Heo-Giá-thấp', '8. Heo-Mã điểm đo-cao', '8. Heo-Số lượng nuôi-cao', '8. Heo-Số trang trại-cao']\n","list_lag+=list_lag2\n","list_fu=['NAM', 'THANG', 'STT_THANG', 'NUM_DAY_OF_MONTH','Holidays', 'Holidays date', 'Holidays numdays', 'Covid', 'Ukraine war']\n","list_fu+=list_weather\n","list_static=['LAT','LONG']"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"90f65c4c-44a4-4707-94ce-3e4473921779","_uuid":"c575eef9-1877-45f1-9582-f72f30c2b525","collapsed":false,"execution":{"iopub.execute_input":"2024-06-06T09:42:32.177145Z","iopub.status.busy":"2024-06-06T09:42:32.176888Z","iopub.status.idle":"2024-06-06T09:42:37.612785Z","shell.execute_reply":"2024-06-06T09:42:37.611992Z","shell.execute_reply.started":"2024-06-06T09:42:32.177117Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["df=pd.read_excel('San_luong_thuong_pham_dmtmn_theo_thang_06_06_2024.xlsx')\n","df['ds'] = pd.PeriodIndex(year=df['NAM'], month=df['THANG'], freq='M')\n","df['ds'] = df['ds'].dt.to_timestamp()\n","df=df.loc[df['ds']<='2024-07-01']\n","df.drop(columns=['NAM_THANG','THUONG_PHAM_D1M_TB','THUONG_PHAM','THUONG_PHAM_TB','THUONG_PHAM_T1M','THUONG_PHAM_T1M_TB'],inplace=True)\n","df.pivot(index='ds',columns='MA_DVIQLY',values='THUONG_PHAM_D1M')"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a493131c-becd-442d-93bd-c0f916cc93be","_uuid":"768c4299-3bbd-47e4-abfd-b16c95c05185","collapsed":false,"execution":{"iopub.execute_input":"2024-06-06T09:42:45.625047Z","iopub.status.busy":"2024-06-06T09:42:45.624776Z","iopub.status.idle":"2024-06-06T09:42:45.645145Z","shell.execute_reply":"2024-06-06T09:42:45.644276Z","shell.execute_reply.started":"2024-06-06T09:42:45.625022Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["dfp=df.pivot(index='ds',columns='MA_DVIQLY',values='THUONG_PHAM_D1M')\n","dfp['total']=dfp.sum(axis=1)\n","dfp.tail(4)"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f13cf41e-e34e-4dd0-bea7-bb254c7f6439","_uuid":"38a4daa4-facb-4571-94d2-82508cdf3f35","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["# df=df.loc[df['ds']<='2024-01-01']\n","# fu=df[df['ds']>='2023-12-01']\n","# fu.loc[:,list_y+list_lag]=None\n","# fu.loc[:,'ds']=fu['ds']+pd.DateOffset(months=+2) #dataframe future 1 tháng\n","# fu.loc[:,'NAM']=fu['ds'].dt.year\n","# fu.loc[:,'THANG']=fu['ds'].dt.month\n","# fu.loc[:,'NUM_DAY_OF_MONTH']=fu['ds'].dt.days_in_month\n","# df=pd.concat([df,fu])\n","# df.set_index('ds', inplace=True)\n","# df.drop(columns='NUM_DAY_OF_MONTH.1',inplace=True)\n","# df[df['MA_DVIQLY']=='PC10AA']"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3d0028f0-2538-4bfd-910b-02ffae67a159","_uuid":"5e06cfd6-c0ab-4e16-bd03-d1bac06c449f","collapsed":false,"execution":{"iopub.execute_input":"2024-06-06T09:42:55.402525Z","iopub.status.busy":"2024-06-06T09:42:55.402257Z","iopub.status.idle":"2024-06-06T09:42:55.702972Z","shell.execute_reply":"2024-06-06T09:42:55.702148Z","shell.execute_reply.started":"2024-06-06T09:42:55.402496Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["# df=df.loc[df['ds']<='2024-04-01']\n","# fu=df[df['ds']>='2024-03-01']\n","# fu.loc[:,list_y+list_lag]=None\n","# fu.loc[:,'ds']=fu['ds']+pd.DateOffset(months=+2) #dataframe future 1 tháng\n","# fu.loc[:,'NAM']=fu['ds'].dt.year\n","# fu.loc[:,'THANG']=fu['ds'].dt.month\n","# fu.loc[:,'NUM_DAY_OF_MONTH']=fu['ds'].dt.days_in_month\n","# df=pd.concat([df,fu])\n","df.set_index('ds', inplace=True)\n","df[df['MA_DVIQLY']=='PC10AA']"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c421ea45-bef3-46de-9068-615c87b36dbd","_uuid":"b2d51f53-2615-4ede-a826-43df53f6dd91","collapsed":false,"execution":{"iopub.execute_input":"2024-06-06T09:43:05.151617Z","iopub.status.busy":"2024-06-06T09:43:05.151339Z","iopub.status.idle":"2024-06-06T09:43:05.192643Z","shell.execute_reply":"2024-06-06T09:43:05.191742Z","shell.execute_reply.started":"2024-06-06T09:43:05.151587Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["df[df['MA_DVIQLY']=='PC10AA'][list_fu]"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4909a0b5-5c61-4ef2-aee9-5e52cc738682","_uuid":"ac523c1c-e56d-4ade-8f8a-c0388710e9ef","collapsed":false,"execution":{"iopub.execute_input":"2024-06-06T09:43:11.753193Z","iopub.status.busy":"2024-06-06T09:43:11.752392Z","iopub.status.idle":"2024-06-06T09:43:12.274915Z","shell.execute_reply":"2024-06-06T09:43:12.273923Z","shell.execute_reply.started":"2024-06-06T09:43:11.753156Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["y=  TimeSeries.from_group_dataframe(df=df,group_cols='MA_DVIQLY',value_cols=list_y,static_cols=list_static)\n","lag=TimeSeries.from_group_dataframe(df=df,group_cols='MA_DVIQLY',value_cols=list_lag,static_cols=list_static)\n","fu=TimeSeries.from_group_dataframe(df=df,group_cols='MA_DVIQLY',value_cols=list_fu,static_cols=list_static)\n","\n","scaler_y=Scaler()\n","scaler_lag=Scaler()\n","scaler_fu=Scaler()\n","scaler_static_y=StaticCovariatesTransformer()\n","scaler_static_lag=StaticCovariatesTransformer()\n","scaler_static_fu=StaticCovariatesTransformer()\n","\n","y=  scaler_static_y.fit_transform(y)\n","lag=scaler_static_lag.fit_transform(lag)\n","fu= scaler_static_fu.fit_transform(fu)\n","\n","nom_y=  scaler_y.fit_transform(y)\n","nom_lag=scaler_lag.fit_transform(lag)\n","nom_fu= scaler_fu.fit_transform(fu)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["nom_fu[0].pd_dataframe()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# from pytorch_lightning.callbacks import RichProgressBar\n","# from pytorch_lightning.callbacks.progress.rich_progress import RichProgressBarTheme\n","\n","# # create your own theme!\n","# progress_bar = RichProgressBar(\n","#     theme=RichProgressBarTheme(\n","#         description=\"green_yellow\",\n","#         progress_bar=\"green1\",\n","#         progress_bar_finished=\"green1\",\n","#         progress_bar_pulse=\"#6206E0\",\n","#         batch_progress=\"green_yellow\",\n","#         time=\"grey82\",\n","#         processing_speed=\"grey82\",\n","#         metrics=\"grey82\",\n","#         metrics_text_delimiter=\"\\n\",\n","#         metrics_format=\".3e\",\n","#     )\n","# )\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-06T07:08:51.534322Z","iopub.status.busy":"2024-06-06T07:08:51.533593Z","iopub.status.idle":"2024-06-06T07:08:51.538923Z","shell.execute_reply":"2024-06-06T07:08:51.538103Z","shell.execute_reply.started":"2024-06-06T07:08:51.534287Z"},"trusted":true},"outputs":[],"source":["# %pdb off"]},{"cell_type":"code","execution_count":23,"metadata":{"_cell_guid":"c05063b8-8d7c-4c56-b293-319b9d47129f","_uuid":"00602bed-bb14-428c-9ed6-d1732056c319","execution":{"iopub.execute_input":"2024-06-06T10:56:26.245246Z","iopub.status.busy":"2024-06-06T10:56:26.244684Z","iopub.status.idle":"2024-06-06T11:53:18.108304Z","shell.execute_reply":"2024-06-06T11:53:18.107302Z","shell.execute_reply.started":"2024-06-06T10:56:26.245211Z"},"trusted":true},"outputs":[],"source":["results1=None\n","results2=None\n","# metric=torchmetrics.MeanAbsoluteError()\n","metric=torchmetrics.MeanAbsoluteError()\n","for i in range(0,3):\n","    back_step=i\n","    n_step=2\n","    len_val=1\n","    input_chunk_length=25\n","\n","    train_y  =[i[:-n_step-back_step-len_val] for i in nom_y]\n","    train_lag=[i[:-n_step-back_step-len_val] for i in nom_lag]\n","    train_fu =[i[:-n_step-back_step-len_val] for i in nom_fu] # if back_step>0 else [i for i in nom_fu]\n","\n","    val_y    =[i[-input_chunk_length-n_step-back_step-len_val-1:-n_step-back_step] for i in nom_y]\n","    val_lag  =[i[-input_chunk_length-n_step-back_step-len_val-1:-n_step-back_step] for i in nom_lag]\n","    val_fu   =[i[-input_chunk_length-n_step-back_step-len_val-1:-n_step-back_step] for i in nom_fu] #if back_step>0 else [i[-len_val-input_chunk_length:] for i in nom_fu]\n","    \n","    test_y  =[i[-input_chunk_length-n_step-back_step:-n_step-back_step] for i in nom_y]\n","    test_lag=[i[-input_chunk_length-n_step-back_step:-n_step-back_step] for i in nom_lag]\n","    test_fu =[i[-input_chunk_length-n_step-back_step:-back_step] for i in nom_fu] if back_step>0 else [i[-input_chunk_length-n_step-back_step:] for i in nom_fu]\n","\n","    val_metric=[i[-n_step-back_step:-back_step] for i in nom_y] if back_step>0 else [i[-n_step:] for i in nom_y]\n","    # if i ==0:\n","    #     ipdb.set_trace()\n","    model = TiDEModel(\n","        input_chunk_length=input_chunk_length,\n","        output_chunk_length=n_step,\n","        n_epochs=2,\n","        num_encoder_layers=4,\n","        num_decoder_layers=4,\n","        decoder_output_dim=32,\n","        torch_metrics=metric,\n","        hidden_size=512,\n","        temporal_width_past=64,\n","        temporal_width_future=64,\n","#         use_layer_norm=True,\n","        loss_fn=CustomLoss(),\n","        random_state=45,\n","        batch_size=15,\n","        dropout=0.5,\n","        activation=SwiGLU,\n","        monitor_checkpoint=\"val_MeanAbsoluteError\",\n","        optimizer_cls=torch.optim.AdamW,\n","        optimizer_kwargs={\"lr\": 4e-4, \"amsgrad\":True, \"eps\":1e-12},\n","        model_name='my_model',\n","        save_checkpoints=True,\n","        force_reset=True,\n","        use_reversible_instance_norm=True,\n","        pl_trainer_kwargs= {\"accelerator\": \"gpu\",\"precision\":\"64-true\",\n","            \"callbacks\": [TFMProgressBar(enable_train_bar_only=True,dynamic_ncols=True,refresh_rate=20,)],\n","            \"limit_train_batches\":0.2,\n","        },\n","    )\n","\n","    # model.trainer_params[\"enable_progress_bar\"] = False\n","    model.fit(train_y,train_lag,train_fu,val_y,val_lag,val_fu)\n","    print(sorted([os.path.basename(path) for path in glob.glob('/kaggle/working/*/*/*/*')]))\n","    best_model = model.load_from_checkpoint(model_name='my_model', best=True)\n","    pred_list = scaler_static_y.inverse_transform(scaler_y.inverse_transform(best_model.predict(n=n_step, series=test_y, past_covariates=test_lag, future_covariates=test_fu)))\n","#     total=concatenate(pred_list,axis=0).pd_dataframe()\n","    total=pd.concat([pred_list[i]['THUONG_PHAM_D1M'].pd_dataframe() for i in range(len(pred_list))],axis=1,)\n","    total.columns=[pred_list[i].static_covariates['MA_DVIQLY']['THUONG_PHAM_D1M'] for i in range(len(pred_list))]\n","    total['PC10']=total.sum(axis=1)\n","    total=total.tail(2)\n","    \n","    results1 = total.head(1) if results1 is None else pd.concat([total.head(1),results1])\n","    results2 = total.tail(1) if results2 is None else pd.concat([total.tail(1),results2])\n","    print(total['PC10'])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["metric.plot()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["A=pd.concat([dfp.tail(19)['total'],results1['PC10']],axis=1)\n","A['sai_so_1T_%']=(A['PC10']-A['total'])/A['PC10']*100\n","A=A.rename(columns={'total':'thuc_te','PC10':'du_bao_truoc_1T'})\n","A=pd.concat([A,results2['PC10']],axis=1)\n","A['sai_so_2T_%']=(A['PC10']-A['thuc_te'])/A['PC10']*100\n","A=A.rename(columns={'PC10':'du_bao_truoc_2T'})\n","A"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["A=pd.concat([dfp.tail(19)['total'],results1['PC10']],axis=1)\n","A['sai_so_1T_%']=(A['PC10']-A['total'])/A['PC10']*100\n","A=A.rename(columns={'total':'thuc_te','PC10':'du_bao_truoc_1T'})\n","A=pd.concat([A,results2['PC10']],axis=1)\n","A['sai_so_2T_%']=(A['PC10']-A['thuc_te'])/A['PC10']*100\n","A=A.rename(columns={'PC10':'du_bao_truoc_2T'})\n","A"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# from lightning.pytorch.loggers import TensorBoardLogger\n","# logger = TensorBoardLogger(\"tb_logs\", name=\"my_model\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# results1=None\n","# results2=None\n","# metric=torchmetrics.MeanAbsoluteError()\n","# # metric=torchmetrics.MeanAbsolutePercentageError()\n","# for i in range(0,8):\n","#     back_step=i\n","#     n_step=2\n","#     len_val=4\n","#     input_chunk_length=25\n","\n","#     train_y  =[i[:-n_step-back_step-len_val+len_val] for i in nom_y]\n","#     train_lag=[i[:-n_step-back_step-len_val+len_val] for i in nom_lag]\n","#     train_fu =[i[:-back_step-len_val+len_val] for i in nom_fu] if back_step>0 else [i for i in nom_fu]\n","\n","#     val_y    =[i[-len_val-input_chunk_length-back_step:-n_step-back_step] for i in nom_y]\n","#     val_lag  =[i[-len_val-input_chunk_length-back_step:-n_step-back_step] for i in nom_lag]\n","#     val_fu   =[i[-len_val-input_chunk_length-back_step:-back_step] for i in nom_fu] \\\n","#                 if back_step>0 else [i[-len_val-input_chunk_length:] for i in nom_fu]\n","\n","#     test_y  =[i[:-n_step-back_step] for i in nom_y]\n","#     test_lag=[i[:-n_step-back_step] for i in nom_lag]\n","#     test_fu =[i[:-back_step] for i in nom_fu] if back_step>0 else [i for i in nom_fu]\n","\n","#     val_metric=[i[-n_step-back_step:-back_step] for i in nom_y] if back_step>0 else [i[-n_step:] for i in nom_y]\n"," \n","#     model = iTransformerModel(\n","#         input_chunk_length=input_chunk_length,\n","#         output_chunk_length=n_step,\n","#         n_epochs=50,\n","#         num_encoder_layers=8,\n","#         num_decoder_layers=5,\n","#         d_model=128,\n","#         nhead=16,\n","#         # decoder_output_dim=32,\n","#         torch_metrics=metric,\n","#         # hidden_size=128,\n","# #         use_layer_norm=True,\n","#         loss_fn=CustomLoss(),\n","#         random_state=100,\n","#         batch_size=32,\n","#         dropout=0.2,\n","#         activation='SwiGLU',\n","#         monitor_checkpoint=\"val_MeanAbsoluteError\",\n","# #         use_layer_norm=True,\n","#         optimizer_cls=torch.optim.AdamW,\n","#         optimizer_kwargs={\"lr\": 5e-4,\n","#                           \"amsgrad\":True,\n","#                           \"eps\":1e-12},\n","# #         lr_scheduler_cls=torch.optim.lr_scheduler.CosineAnnealingLR,\n","# #         lr_scheduler_kwargs = {\"T_max\":25, \"eta_min\":1e-4},\n","#         model_name='my_model', \n","#         save_checkpoints=True,\n","# #         log_tensorboard=True,\n","#         force_reset=True,\n","#         use_reversible_instance_norm=True,\n","#         pl_trainer_kwargs= {\n","#             \"accelerator\": \"gpu\",\n","#             \"callbacks\": [TFMProgressBar(enable_train_bar_only=True,refresh_rate=50,)],\n","#             \"limit_train_batches\":0.2,\n","#             \"precision\":\"64-true\",\n","#         },\n","#     )\n","\n","#     # model.trainer_params[\"enable_progress_bar\"] = False\n"," \n","#     model.fit(train_y,train_lag,None,val_y,val_lag,None)\n","#     print(sorted(glob.glob('/kaggle/working/*/*/*/*')))\n","#     best_model = model.load_from_checkpoint(model_name='my_model', best=True)\n","#     pred_list = scaler_y.inverse_transform(best_model.predict(n=n_step, series=test_y, past_covariates=test_lag, future_covariates=None))\n","# #     total=concatenate(pred_list,axis=0).pd_dataframe()\n","#     total=pd.concat([pred_list[i]['THUONG_PHAM_D1M'].pd_dataframe() for i in range(len(pred_list))],axis=1,)\n","#     total.columns=[pred_list[i].static_covariates['MA_DVIQLY']['THUONG_PHAM_D1M'] for i in range(len(pred_list))]\n","#     total['PC10']=total.sum(axis=1)\n","#     total=total.tail(2)\n","    \n","#     results1 = total.head(1) if results1 is None else pd.concat([total.head(1),results1])\n","#     results2 = total.tail(1) if results2 is None else pd.concat([total.tail(1),results2])\n","#     print(total['PC10'])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["%load_ext tensorboard"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["%tensorboard --logdir /kaggle/working/darts_logs/my_model/logs/"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3f39a1d9-3201-4189-a934-82799356028f","_uuid":"e387817f-dea8-4f32-9059-bcd0fa1833dc","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["# test=[8,7,6,5,4,3,2,1]\n","# test[-6:],test[:-1],test[-6:-1]"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8a92dede-c42c-4f7e-bd46-4594ac1c84d3","_uuid":"42ef84ca-7ff8-4826-8570-9ee013ca40d1","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["# back_step=1\n","# n_step=2\n","# len_val=35\n","\n","# train_y  =[i[:-n_step-back_step] for i in nom_y]\n","# train_lag=[i[:-n_step-back_step] for i in nom_lag]\n","# train_fu =[i[:-back_step] for i in nom_fu] if back_step>0 else [i for i in nom_fu]\n","\n","# val_y    =[i[-len_val-back_step:-n_step-back_step] for i in nom_y]\n","# val_lag  =[i[-len_val-back_step:-n_step-back_step] for i in nom_lag]\n","# val_fu   =[i[-len_val-back_step:-back_step] for i in nom_fu] if back_step>0 else [i[-len_val:] for i in nom_fu]\n","\n","# val_metric=[i[-n_step-back_step:-back_step] for i in nom_y] if back_step>0 else [i[-n_step:] for i in nom_y]"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4ba6fd28-22b5-4d2e-a3f9-ec87f0a8767f","_uuid":"0bab21e7-09e5-4762-b229-2efdba8c53f8","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["nom_fu[0].pd_dataframe()"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a032f77f-faf2-442b-b7d1-48330c751347","_uuid":"6dac9c65-cd84-409f-80f0-4a4c9d44fa2d","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["nom_lag[1].static_covariates"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"70f82bbb-27c4-4885-af42-1aa245bec035","_uuid":"a3c49950-7996-4ecf-8b5f-3c43680f0e90","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["lag[4].static_covariates"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"026c8412-3350-4826-9cd3-520de4789886","_uuid":"9013d3fe-1878-405a-bd88-cdace7f3ca06","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["# %%time\n","# model = TiDEModel(\n","#     input_chunk_length=25,\n","#     output_chunk_length=2,\n","#     n_epochs=50,\n","#     random_state=0,\n","#     batch_size=64,\n","#     model_name='my_model', save_checkpoints=True,\n","#     force_reset=True,\n","#     use_reversible_instance_norm=True,\n","#     **generate_torch_kwargs()\n","# )\n","\n","# # model.trainer_params[\"enable_progress_bar\"] = False\n","# model.fit(train_y,train_lag,train_fu,val_y,val_lag,val_fu)\n","# print(glob.glob('/kaggle/working/*/*/*/*'))\n","# # model.fit(nom_y,past_covariates=nom_lag,future_covariates=nom_fu)\n","# best_model = model.load_from_checkpoint(model_name='my_model', best=True)\n","# pred_list = scaler_y.inverse_transform(best_model.predict(n=2, series=train_y, past_covariates=train_lag, future_covariates=train_fu))\n","# total=concatenate(pred_list,axis=1).pd_dataframe()\n","# total['PC10']=total.sum(axis=1)\n","# total"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9c615321-fc8f-46a5-8f5d-66775abe5c16","_uuid":"c9b0552d-6a85-4c9d-90e7-c81d3d6ec2e6","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["# dfp.tail(6)"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2b994e92-b7a0-4e61-b4bc-c0ad634eca4e","_uuid":"c6499d2b-ee30-4d82-a18b-533e8e6e3d90","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["%pdb on"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"bd4f2761-62ce-4c63-92e9-1651a1911ca2","_uuid":"4d1e582a-2d11-4d79-b324-1a58c562399d","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["# print(glob.glob('/kaggle/working/*/*/*/*'))"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d0ad9ed2-6503-42de-bfc9-b37f80b8d577","_uuid":"f88a3e4b-6d83-4ab7-a0f5-ed5345ff2d66","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["# results=None\n","\n","# for i in range(0,12):\n","#     back_step=i\n","#     n_step=2\n","#     len_val=35\n","\n","#     train_y  =[i[:-n_step-back_step] for i in nom_y]\n","#     train_lag=[i[:-n_step-back_step] for i in nom_lag]\n","#     train_fu =[i[:-back_step] for i in nom_fu] if back_step>0 else [i for i in nom_fu]\n","\n","#     val_y    =[i[-len_val-back_step:-n_step-back_step] for i in nom_y]\n","#     val_lag  =[i[-len_val-back_step:-n_step-back_step] for i in nom_lag]\n","#     val_fu   =[i[-len_val-back_step:-back_step] for i in nom_fu] if back_step>0 else [i[-len_val:] for i in nom_fu]\n","\n","#     val_metric=[i[-n_step-back_step:-back_step] for i in nom_y] if back_step>0 else [i[-n_step:] for i in nom_y]\n","\n","#     model = TiDEModel(\n","#         input_chunk_length=25,\n","#         output_chunk_length=2,\n","#         n_epochs=20,\n","#         num_encoder_layers=3,\n","#         num_decoder_layers=3,\n","#         decoder_output_dim=32,\n","#         random_state=10,\n","#         batch_size=4,\n","#         dropout=0.2,\n","#         optimizer_kwargs={\"lr\": 5e-5},\n","#         model_name='my_model', save_checkpoints=True,\n","#         force_reset=True,\n","#         use_reversible_instance_norm=True,\n","#         **generate_torch_kwargs()\n","#     )\n","\n","#     # model.trainer_params[\"enable_progress_bar\"] = False\n","#     model.fit(train_y,train_lag,train_fu,val_y,val_lag,val_fu)\n","#     print(glob.glob('/kaggle/working/*/*/*/*'))\n","# #     model.fit(nom_y,past_covariates=nom_lag,future_covariates=nom_fu)\n","#     best_model = model.load_from_checkpoint(model_name='my_model', best=True)\n","#     pred_list = scaler_y.inverse_transform(best_model.predict(n=2, series=train_y, past_covariates=train_lag, future_covariates=train_fu))\n","#     total=concatenate(pred_list,axis=1).pd_dataframe()\n","#     total['PC10']=total.sum(axis=1)\n","#     total=total.tail(1)\n","    \n","#     results = total if results is None else pd.concat([total,results])\n","#     print(total['PC10'])"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"11390cea-4047-432f-aa16-e7a23cca3074","_uuid":"b20a2cdd-5bc1-4cde-8e01-04c7271478ea","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["# from lightning.pytorch.callbacks import Callback\n","\n","# class MyCallback(Callback):\n","#     def on_validation_end(self, trainer, pl_module):\n","#         print('Validation epoch {} ended'.format(trainer.current_epoch))"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1750077b-5f73-4928-8fc0-fbf7f0281af1","_uuid":"4a063228-69f6-4c80-aaa0-be56613809cd","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["from lightning.pytorch import Trainer\n","from lightning.pytorch.callbacks import Callback\n","from lightning.pytorch.demos.boring_classes import BoringDataModule, BoringModel"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d496a7a9-95bd-4b1a-98af-2cbfe22566b5","_uuid":"1e00139f-85e9-4bfb-acfb-dfc3ab17de96","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["class PredictAfterValidationCallback(Callback):\n","    def setup(self, trainer, pl_module, stage):\n","        if stage in (\"fit\", \"validate\"):\n","            # setup the predict data even for fit/validate, as we will call it during `on_validation_epoch_end`\n","            trainer.datamodule.setup(\"validate\")\n","\n","    def on_validation_epoch_end(self, trainer, pl_module):\n","        if trainer.sanity_checking:  # optional skip\n","            return\n","        print(\"Start predicting!\")\n","        # this will fetch the dataloader from the LM or LDM\n","        predict_dataloader = trainer._data_connector._predict_dataloader_source.dataloader()\n","        for i, batch in enumerate(predict_dataloader):\n","            # this will move the batch to device using the LM or LDM\n","            batch = pl_module._apply_batch_transfer_handler(batch)\n","            # manually run the predict step\n","            out = pl_module.predict_step(batch, i)\n","            print(i, out)"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c57e144b-29a0-4705-b50b-616c248bd494","_uuid":"0a77796b-9ae8-48c9-a946-9f4492060f87","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["from darts.utils.losses import MapeLoss"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4d513f3f-97d2-4f09-a0d5-997f3ce68bc4","_uuid":"04bb31a0-672a-4901-871f-2b537bcccd72","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["from darts.metrics.metrics import rmse"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["metric=torchmetrics.MeanAbsolutePercentageError"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9e55aec5-5124-41da-8e1f-3f15a5f5f492","_uuid":"7f097328-1e90-4837-82cf-9736327f1e68","trusted":true},"outputs":[],"source":["def _mean_squared_error_compute(sum_squared_error: Tensor, num_obs: Union[int, Tensor], squared: bool = True) -> Tensor:\n","    \"\"\"Compute Mean Squared Error.\n","\n","    Args:\n","        sum_squared_error: Sum of square of errors over all observations\n","        num_obs: Number of predictions or observations\n","        squared: Returns RMSE value if set to False.\n","\n","    Example:\n","        >>> preds = torch.tensor([0., 1, 2, 3])\n","        >>> target = torch.tensor([0., 1, 2, 2])\n","        >>> sum_squared_error, num_obs = _mean_squared_error_update(preds, target, num_outputs=1)\n","        >>> _mean_squared_error_compute(sum_squared_error, num_obs)\n","        tensor(0.2500)\n","\n","    \"\"\"\n","    return sum_squared_error / num_obs if squared else torch.sqrt(sum_squared_error / num_obs)\n","\n","class MeanSquaredError(Metric):\n","    r\"\"\"Compute `mean squared error`_ (MSE).\n","\n","    .. math:: \\text{MSE} = \\frac{1}{N}\\sum_i^N(y_i - \\hat{y_i})^2\n","\n","    Where :math:`y` is a tensor of target values, and :math:`\\hat{y}` is a tensor of predictions.\n","\n","    As input to ``forward`` and ``update`` the metric accepts the following input:\n","\n","    - ``preds`` (:class:`~torch.Tensor`): Predictions from model\n","    - ``target`` (:class:`~torch.Tensor`): Ground truth values\n","\n","    As output of ``forward`` and ``compute`` the metric returns the following output:\n","\n","    - ``mean_squared_error`` (:class:`~torch.Tensor`): A tensor with the mean squared error\n","\n","    Args:\n","        squared: If True returns MSE value, if False returns RMSE value.\n","        num_outputs: Number of outputs in multioutput setting\n","        kwargs: Additional keyword arguments, see :ref:`Metric kwargs` for more info.\n","\n","    Example::\n","        Single output mse computation:\n","\n","        >>> from torch import tensor\n","        >>> from torchmetrics.regression import MeanSquaredError\n","        >>> target = tensor([2.5, 5.0, 4.0, 8.0])\n","        >>> preds = tensor([3.0, 5.0, 2.5, 7.0])\n","        >>> mean_squared_error = MeanSquaredError()\n","        >>> mean_squared_error(preds, target)\n","        tensor(0.8750)\n","\n","    Example::\n","        Multioutput mse computation:\n","\n","        >>> from torch import tensor\n","        >>> from torchmetrics.regression import MeanSquaredError\n","        >>> target = tensor([[0.0, 0.0, 0.0], [0.0, 0.0, 0.0]])\n","        >>> preds = tensor([[1.0, 2.0, 3.0], [1.0, 2.0, 3.0]])\n","        >>> mean_squared_error = MeanSquaredError(num_outputs=3)\n","        >>> mean_squared_error(preds, target)\n","        tensor([1., 4., 9.])\n","\n","    \"\"\"\n","\n","    is_differentiable = True\n","    higher_is_better = False\n","    full_state_update = False\n","    plot_lower_bound: float = 0.0\n","\n","    sum_squared_error: Tensor\n","    total: Tensor\n","\n","    def __init__(\n","        self,\n","        squared: bool = True,\n","        num_outputs: int = 1,\n","        **kwargs: Any,\n","    ) -> None:\n","        super().__init__(**kwargs)\n","\n","        if not isinstance(squared, bool):\n","            raise ValueError(f\"Expected argument `squared` to be a boolean but got {squared}\")\n","        self.squared = squared\n","\n","        if not (isinstance(num_outputs, int) and num_outputs > 0):\n","            raise ValueError(f\"Expected num_outputs to be a positive integer but got {num_outputs}\")\n","        self.num_outputs = num_outputs\n","\n","        self.add_state(\"sum_squared_error\", default=torch.zeros(num_outputs), dist_reduce_fx=\"sum\")\n","        self.add_state(\"total\", default=tensor(0), dist_reduce_fx=\"sum\")\n","\n","    def update(self, preds: Tensor, target: Tensor) -> None:\n","        \"\"\"Update state with predictions and targets.\"\"\"\n","        sum_squared_error, num_obs = _mean_squared_error_update(preds, target, num_outputs=self.num_outputs)\n","\n","        self.sum_squared_error += sum_squared_error\n","        self.total += num_obs\n","\n","    def compute(self) -> Tensor:\n","        \"\"\"Compute mean squared error over state.\"\"\"\n","        return _mean_squared_error_compute(self.sum_squared_error, self.total, squared=self.squared)\n","\n","    def plot(\n","        self, val: Optional[Union[Tensor, Sequence[Tensor]]] = None, ax: Optional[_AX_TYPE] = None\n","    ) -> _PLOT_OUT_TYPE:\n","        \"\"\"Plot a single or multiple values from the metric.\n","\n","        Args:\n","            val: Either a single result from calling `metric.forward` or `metric.compute` or a list of these results.\n","                If no value is provided, will automatically call `metric.compute` and plot that result.\n","            ax: An matplotlib axis object. If provided will add plot to that axis\n","\n","        Returns:\n","            Figure and Axes object\n","\n","        Raises:\n","            ModuleNotFoundError:\n","                If `matplotlib` is not installed\n","\n","        .. plot::\n","            :scale: 75\n","\n","            >>> from torch import randn\n","            >>> # Example plotting a single value\n","            >>> from torchmetrics.regression import MeanSquaredError\n","            >>> metric = MeanSquaredError()\n","            >>> metric.update(randn(10,), randn(10,))\n","            >>> fig_, ax_ = metric.plot()\n","\n","        .. plot::\n","            :scale: 75\n","\n","            >>> from torch import randn\n","            >>> # Example plotting multiple values\n","            >>> from torchmetrics.regression import MeanSquaredError\n","            >>> metric = MeanSquaredError()\n","            >>> values = []\n","            >>> for _ in range(10):\n","            ...     values.append(metric(randn(10,), randn(10,)))\n","            >>> fig, ax = metric.plot(values)\n","\n","        \"\"\"\n","        return self._plot(val, ax)"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8bf6cba6-d3f3-4aac-a4d9-0c21f885342f","_uuid":"bcbca9cf-dead-4096-a80c-4b4a3317f41b","trusted":true},"outputs":[],"source":["# results1=None\n","# results2=None\n","\n","# for i in range(0,18):\n","#     back_step=i\n","#     n_step=2\n","#     len_val=4\n","#     input_chunk_length=25\n","\n","#     train_y  =[i[:-n_step-back_step-len_val+len_val] for i in nom_y]\n","#     train_lag=[i[:-n_step-back_step-len_val+len_val] for i in nom_lag]\n","#     train_fu =[i[:-back_step-len_val+len_val] for i in nom_fu] if back_step>0 else [i for i in nom_fu]\n","\n","#     val_y    =[i[-len_val-input_chunk_length-back_step:-n_step-back_step] for i in nom_y]\n","#     val_lag  =[i[-len_val-input_chunk_length-back_step:-n_step-back_step] for i in nom_lag]\n","#     val_fu   =[i[-len_val-input_chunk_length-back_step:-back_step] for i in nom_fu] \\\n","#                 if back_step>0 else [i[-len_val-input_chunk_length:] for i in nom_fu]\n","#     test_y  =[i[:-n_step-back_step] for i in nom_y]\n","#     test_lag=[i[:-n_step-back_step] for i in nom_lag]\n","#     test_fu =[i[:-back_step] for i in nom_fu] if back_step>0 else [i for i in nom_fu]\n","\n","#     val_metric=[i[-n_step-back_step:-back_step] for i in nom_y] if back_step>0 else [i[-n_step:] for i in nom_y]\n","# #     ipdb.set_trace()\n","#     model = TFTModel(\n","#         input_chunk_length=input_chunk_length,\n","#         output_chunk_length=n_step,\n","#         n_epochs=200,\n","# #         num_encoder_layers=5,\n","# #         num_decoder_layers=5,\n","# #         decoder_output_dim=32,\n","#         torch_metrics=torchmetrics.MeanAbsolutePercentageError(),\n","# #         hidden_size=32,\n","# #         use_layer_norm=True,\n","# #         loss_fn=LogCoshLoss(),\n","#         random_state=50,\n","#         batch_size=32,\n","#         dropout=0.2,\n","# #         activation=\"SwiGLU\",\n","# #         use_layer_norm=True,\n","#         optimizer_cls=torch.optim.AdamW,\n","#         optimizer_kwargs={\"lr\": 1e-4,\n","#                           \"amsgrad\":True,\n","#                           \"eps\":1e-10},\n","#         model_name='my_model', save_checkpoints=True,\n","#         force_reset=True,\n","#         use_reversible_instance_norm=True,\n","#         pl_trainer_kwargs= {\n","#             \"accelerator\": \"cpu\",\n","#             \"callbacks\": [TFMProgressBar(enable_train_bar_only=True,refresh_rate=50,)],\n","# #             \"limit_train_batches\":0.2,\n","#         },\n","#     )\n","\n","#     # model.trainer_params[\"enable_progress_bar\"] = False\n","#     model.fit(train_y,past_covariates=train_lag,future_covariates=train_fu,val_series=val_y,val_past_covariates=val_lag,val_future_covariates=val_fu,)\n","#     print(sorted(glob.glob('/kaggle/working/*/*/*/*')))\n","#     best_model = model.load_from_checkpoint(model_name='my_model', best=True)\n","#     pred_list = scaler_static_y.inverse_transform(scaler_y.inverse_transform(model.predict(n=n_step, series=test_y, past_covariates=test_lag)))\n","# #     total=concatenate(pred_list,axis=0).pd_dataframe()\n","#     total=pd.concat([pred_list[i]['THUONG_PHAM_D1M'].pd_dataframe() for i in range(len(pred_list))],axis=1,)\n","#     total.columns=[pred_list[i].static_covariates['MA_DVIQLY']['THUONG_PHAM_D1M'] for i in range(len(pred_list))]\n","#     total['PC10']=total.sum(axis=1)\n","#     total=total.tail(2)\n","    \n","#     results1 = total.head(1) if results1 is None else pd.concat([total.head(1),results1])\n","#     results2 = total.tail(1) if results2 is None else pd.concat([total.tail(1),results2])\n","#     print(total['PC10'])"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f8e0321d-5e7e-4343-b5fd-8339f348b9c5","_uuid":"3bba076f-1ed1-4eb6-ab65-bb4908bdafde","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["A=SwiGLU(10,10)"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"11dd5887-5c1f-42f5-91ef-265b8d206dfb","_uuid":"4a61748e-6c5d-40ec-8d8a-8d9fd13a442a","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["pred_list = scaler_static_y.inverse_transform(scaler_y.inverse_transform(model.predict(n=n_step, series=test_y, past_covariates=test_lag, future_covariates=test_fu)))"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0d4ed110-47ac-4068-a351-e83b974365c8","_uuid":"5d2923b5-e447-4e5e-8e5e-ea7d893ab7d5","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["torchmetrics.Me"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"734a5269-f60f-4b18-afd3-6081d70385e9","_uuid":"9fea8d05-96b4-4a2f-9498-888737626c40","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["torchmetrics.MeanAbsolutePercentageError"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7023773a-364f-4c56-8a51-e139a9881d8c","_uuid":"ad1e6d6b-a0fb-48c1-8c39-418506e401e7","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["total=pd.concat([pred_list[i]['THUONG_PHAM_D1M'].pd_dataframe() for i in range(len(pred_list))],axis=1,)\n","total.columns=[pred_list[i].static_covariates['MA_DVIQLY']['THUONG_PHAM_D1M'] for i in range(len(pred_list))]\n","total['PC10']=total.sum(axis=1)\n","total"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"abd847a4-7ee5-40b4-b5b3-5093b81c5acd","_uuid":"a6595d3e-26f4-4490-98d7-51f300134848","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["pred_list = scaler_y.inverse_transform(model.predict(n=n_step, series=test_y, past_covariates=test_lag, future_covariates=test_fu))\n","total=concatenate(pred_list,axis=1).pd_dataframe()\n","total['PC10']=total.sum(axis=1)\n","total=total.tail(2)\n","total"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["A=pd.concat([dfp.tail(19)['total'],results1['PC10']],axis=1)\n","A['sai_so_1T_%']=(A['PC10']-A['total'])/A['PC10']*100\n","A=A.rename(columns={'total':'thuc_te','PC10':'du_bao_truoc_1T'})\n","A=pd.concat([A,results2['PC10']],axis=1)\n","A['sai_so_2T_%']=(A['PC10']-A['thuc_te'])/A['PC10']*100\n","A=A.rename(columns={'PC10':'du_bao_truoc_2T'})\n","A"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["A=pd.concat([dfp.tail(19)['total'],results1['PC10']],axis=1)\n","A['sai_so_1T_%']=(A['PC10']-A['total'])/A['PC10']*100\n","A=A.rename(columns={'total':'thuc_te','PC10':'du_bao_truoc_1T'})\n","A=pd.concat([A,results2['PC10']],axis=1)\n","A['sai_so_2T_%']=(A['PC10']-A['thuc_te'])/A['PC10']*100\n","A=A.rename(columns={'PC10':'du_bao_truoc_2T'})\n","A"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d1683ae8-fba0-4bbd-8bc4-e6563279a967","_uuid":"3d5c3778-42f3-40be-9dee-42d5d395b2bb","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["A=pd.concat([dfp.tail(19)['total'],results1['PC10']],axis=1)\n","A['sai_so_1T_%']=(A['PC10']-A['total'])/A['PC10']*100\n","A=A.rename(columns={'total':'thuc_te','PC10':'du_bao_truoc_1T'})\n","A=pd.concat([A,results2['PC10']],axis=1)\n","A['sai_so_2T_%']=(A['PC10']-A['thuc_te'])/A['PC10']*100\n","A=A.rename(columns={'PC10':'du_bao_truoc_2T'})\n","A"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6755cb28-d1d8-43f2-a0a0-c0eded64de8a","_uuid":"78b8c571-0b3b-4cd6-b48c-8bdac10d9130","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["A=pd.concat([dfp.tail(19)['total'],results1['PC10']],axis=1)\n","A['sai_so_1T_%']=(A['PC10']-A['total'])/A['PC10']*100\n","A=A.rename(columns={'total':'thuc_te','PC10':'du_bao_truoc_1T'})\n","A=pd.concat([A,results2['PC10']],axis=1)\n","A['sai_so_2T_%']=(A['PC10']-A['thuc_te'])/A['PC10']*100\n","A=A.rename(columns={'PC10':'du_bao_truoc_2T'})\n","A"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2dcd2f0b-72c0-4fad-9c0e-ccc0c81bf1e5","_uuid":"1137e94e-05c7-4988-853d-c3786ca57291","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["A=pd.concat([dfp.tail(19)['total'],results1['PC10']],axis=1)\n","A['sai_so_1T_%']=(A['PC10']-A['total'])/A['PC10']*100\n","A=A.rename(columns={'total':'thuc_te','PC10':'du_bao_truoc_1T'})\n","A=pd.concat([A,results2['PC10']],axis=1)\n","A['sai_so_2T_%']=(A['PC10']-A['thuc_te'])/A['PC10']*100\n","A=A.rename(columns={'PC10':'du_bao_truoc_2T'})\n","A"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0d5a6d79-292f-48c1-bb42-7b9849c7572c","_uuid":"d76c7a35-6093-45dc-95f3-999962c7a3ff","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["A=pd.concat([dfp.tail(19)['total'],results1['PC10']],axis=1)\n","A['sai_so_1T_%']=(A['PC10']-A['total'])/A['PC10']*100\n","A=A.rename(columns={'total':'thuc_te','PC10':'du_bao_truoc_1T'})\n","A=pd.concat([A,results2['PC10']],axis=1)\n","A['sai_so_2T_%']=(A['PC10']-A['thuc_te'])/A['PC10']*100\n","A=A.rename(columns={'PC10':'du_bao_truoc_2T'})\n","A"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b6a4746f-5c1f-4774-b5c1-b6dceba779dd","_uuid":"38dc263e-92db-4340-9367-fa1b6087ca46","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["A=pd.concat([dfp.tail(19)['total'],results1['PC10']],axis=1)\n","A['sai_so_1T_%']=(A['PC10']-A['total'])/A['PC10']*100\n","A=A.rename(columns={'total':'thuc_te','PC10':'du_bao_truoc_1T'})\n","A=pd.concat([A,results2['PC10']],axis=1)\n","A['sai_so_2T_%']=(A['PC10']-A['thuc_te'])/A['PC10']*100\n","A=A.rename(columns={'PC10':'du_bao_truoc_2T'})\n","A"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"44e54e83-9900-4ea4-bfe3-19dcec8ed813","_uuid":"23af2dc9-fddf-49be-b905-62458eee9b49","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["A=pd.concat([dfp.tail(19)['total'],results1['PC10']],axis=1)\n","A['sai_so_1T_%']=(A['PC10']-A['total'])/A['PC10']*100\n","A=A.rename(columns={'total':'thuc_te','PC10':'du_bao_truoc_1T'})\n","A=pd.concat([A,results2['PC10']],axis=1)\n","A['sai_so_2T_%']=(A['PC10']-A['thuc_te'])/A['PC10']*100\n","A=A.rename(columns={'PC10':'du_bao_truoc_2T'})\n","A"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9bbdc503-adae-4282-adce-4c5364f6a3a2","_uuid":"e6cfe2c5-1fd2-4500-9ddb-f9e4dee1887a","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["A=pd.concat([dfp.tail(19)['total'],results1['PC10']],axis=1)\n","A['sai_so_1T_%']=(A['PC10']-A['total'])/A['PC10']*100\n","A=A.rename(columns={'total':'thuc_te','PC10':'du_bao_truoc_1T'})\n","A=pd.concat([A,results2['PC10']],axis=1)\n","A['sai_so_2T_%']=(A['PC10']-A['thuc_te'])/A['PC10']*100\n","A=A.rename(columns={'PC10':'du_bao_truoc_2T'})\n","A"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1c1e80b-12f1-4b43-b30c-0d12f8a42109","_uuid":"306a0447-2219-4fbe-b912-19525835152b","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["A=pd.concat([dfp.tail(19)['total'],results1['PC10']],axis=1)\n","A['sai_so_1T_%']=(A['PC10']-A['total'])/A['PC10']*100\n","A=A.rename(columns={'total':'thuc_te','PC10':'du_bao_truoc_1T'})\n","A=pd.concat([A,results2['PC10']],axis=1)\n","A['sai_so_2T_%']=(A['PC10']-A['thuc_te'])/A['PC10']*100\n","A=A.rename(columns={'PC10':'du_bao_truoc_2T'})\n","A"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8fa5a0ac-e7e3-4c80-ba5a-a20c5ca0de01","_uuid":"0d1fbc24-57f3-4ebf-a8b1-80bd13ad7eed","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["A=pd.concat([dfp.tail(19)['total'],results1['PC10']],axis=1)\n","A['sai_so_1T_%']=(A['PC10']-A['total'])/A['PC10']*100\n","A=A.rename(columns={'total':'thuc_te','PC10':'du_bao_truoc_1T'})\n","A=pd.concat([A,results2['PC10']],axis=1)\n","A['sai_so_2T_%']=(A['PC10']-A['thuc_te'])/A['PC10']*100\n","A=A.rename(columns={'PC10':'du_bao_truoc_2T'})\n","A"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1ae70078-fd16-4619-a2e5-cd67f75b9aa2","_uuid":"df2fa23a-96c5-4089-ae46-41cf33359545","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["A=pd.concat([dfp.tail(19)['total'],results1['PC10']],axis=1)\n","A['sai_so_1T_%']=(A['PC10']-A['total'])/A['PC10']*100\n","A=A.rename(columns={'total':'thuc_te','PC10':'du_bao_truoc_1T'})\n","A=pd.concat([A,results2['PC10']],axis=1)\n","A['sai_so_2T_%']=(A['PC10']-A['thuc_te'])/A['PC10']*100\n","A=A.rename(columns={'PC10':'du_bao_truoc_2T'})\n","A"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2f1452cb-d0ae-4314-a52c-7a4448f39ead","_uuid":"5836b79b-6487-4105-8048-1912527494e8","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["A=pd.concat([dfp.tail(19)['total'],results1['PC10']],axis=1)\n","A['sai_so_1T_%']=(A['PC10']-A['total'])/A['PC10']*100\n","A=A.rename(columns={'total':'thuc_te','PC10':'du_bao_truoc_1T'})\n","A=pd.concat([A,results2['PC10']],axis=1)\n","A['sai_so_2T_%']=(A['PC10']-A['thuc_te'])/A['PC10']*100\n","A=A.rename(columns={'PC10':'du_bao_truoc_2T'})\n","A"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"10a8948f-779a-4192-98ea-275488681f50","_uuid":"651f842f-b5a8-445e-99f1-e8c184068691","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["A=pd.concat([dfp.tail(19)['total'],results1['PC10']],axis=1)\n","A['sai_so_1T_%']=(A['PC10']-A['total'])/A['PC10']*100\n","A=A.rename(columns={'total':'thuc_te','PC10':'du_bao_truoc_1T'})\n","A=pd.concat([A,results2['PC10']],axis=1)\n","A['sai_so_2T_%']=(A['PC10']-A['thuc_te'])/A['PC10']*100\n","A=A.rename(columns={'PC10':'du_bao_truoc_2T'})\n","A"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f0086dd2-dd93-4b4c-8b09-1dc6eacf2b61","_uuid":"0cc8a2c3-e137-4efe-80ce-edd8f15d28bb","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["A=pd.concat([dfp.tail(19)['total'],results1['PC10']],axis=1)\n","A['sai_so_1T_%']=(A['PC10']-A['total'])/A['PC10']*100\n","A=A.rename(columns={'total':'thuc_te','PC10':'du_bao_truoc_1T'})\n","A=pd.concat([A,results2['PC10']],axis=1)\n","A['sai_so_2T_%']=(A['PC10']-A['thuc_te'])/A['PC10']*100\n","A=A.rename(columns={'PC10':'du_bao_truoc_2T'})\n","A"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a33e5749-2e2d-4fad-95ff-3f79bb42e780","_uuid":"9dacc4b9-82fd-4198-9e97-c40a0a6fec3f","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["A=pd.concat([dfp.tail(19)['total'],results1['PC10']],axis=1)\n","A['sai_so_1T_%']=(A['PC10']-A['total'])/A['PC10']*100\n","A=A.rename(columns={'total':'thuc_te','PC10':'du_bao_truoc_1T'})\n","A=pd.concat([A,results2['PC10']],axis=1)\n","A['sai_so_2T_%']=(A['PC10']-A['thuc_te'])/A['PC10']*100\n","A=A.rename(columns={'PC10':'du_bao_truoc_2T'})\n","A"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"99467d32-606a-423b-b2ae-7dbf0c1ea15b","_uuid":"dcc6f733-1655-4eab-9164-c4493b674ebe","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["A=pd.concat([dfp.tail(19)['total'],results1['PC10']],axis=1)\n","A['sai_so_1T_%']=(A['PC10']-A['total'])/A['PC10']*100\n","A=A.rename(columns={'total':'thuc_te','PC10':'du_bao_truoc_1T'})\n","A=pd.concat([A,results2['PC10']],axis=1)\n","A['sai_so_2T_%']=(A['PC10']-A['thuc_te'])/A['PC10']*100\n","A=A.rename(columns={'PC10':'du_bao_truoc_2T'})\n","A"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"fb900274-2b8b-4280-9cf9-48f8942873be","_uuid":"9d6d180a-89de-489c-9b33-95a5b387c5f1","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["A=pd.concat([dfp.tail(19)['total'],results1['PC10']],axis=1)\n","A['sai_so_1T_%']=(A['PC10']-A['total'])/A['PC10']*100\n","A=A.rename(columns={'total':'thuc_te','PC10':'du_bao_truoc_1T'})\n","A=pd.concat([A,results2['PC10']],axis=1)\n","A['sai_so_2T_%']=(A['PC10']-A['thuc_te'])/A['PC10']*100\n","A=A.rename(columns={'PC10':'du_bao_truoc_2T'})\n","A"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"63541b8b-ad13-42bd-933a-8f63d8090300","_uuid":"192600f8-f71c-49da-b6d4-89239ce16fb7","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["A=pd.concat([dfp.tail(19)['total'],results1['PC10']],axis=1)\n","A['sai_so_1T_%']=(A['PC10']-A['total'])/A['PC10']*100\n","A=A.rename(columns={'total':'thuc_te','PC10':'du_bao_truoc_1T'})\n","A=pd.concat([A,results2['PC10']],axis=1)\n","A['sai_so_2T_%']=(A['PC10']-A['thuc_te'])/A['PC10']*100\n","A=A.rename(columns={'PC10':'du_bao_truoc_2T'})\n","A"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2117d694-6b9b-4e6c-af2e-99101369d825","_uuid":"6206b666-3482-484e-adb7-8519eb66c3bf","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["A=pd.concat([dfp.tail(19)['total'],results1['PC10']],axis=1)\n","A['sai_so_1T_%']=(A['PC10']-A['total'])/A['PC10']*100\n","A=A.rename(columns={'total':'thuc_te','PC10':'du_bao_truoc_1T'})\n","A=pd.concat([A,results2['PC10']],axis=1)\n","A['sai_so_2T_%']=(A['PC10']-A['thuc_te'])/A['PC10']*100\n","A=A.rename(columns={'PC10':'du_bao_truoc_2T'})\n","A"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e7ea5744-b963-49aa-b8bb-89948f26cd21","_uuid":"ef31842c-90cc-4b25-b64c-4469d40a2025","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["A=pd.concat([dfp.tail(19)['total'],results1['PC10']],axis=1)\n","A['sai_so_1T_%']=(A['PC10']-A['total'])/A['PC10']*100\n","A=A.rename(columns={'total':'thuc_te','PC10':'du_bao_truoc_1T'})\n","A=pd.concat([A,results2['PC10']],axis=1)\n","A['sai_so_2T_%']=(A['PC10']-A['thuc_te'])/A['PC10']*100\n","A=A.rename(columns={'PC10':'du_bao_truoc_2T'})\n","A"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b9f03569-2a65-48f9-9e8c-c974ef962549","_uuid":"6ef66cc5-79e7-484d-a567-7e9d19d4e139","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["# model = TiDEModel(\n","#     input_chunk_length=15,\n","#     output_chunk_length=2,\n","#     n_epochs=6,\n","# #     random_state=20,\n","#     batch_size=1,\n","#     dropout=0.1,\n","#     optimizer_kwargs={\"lr\": 1e-4},\n","#     model_name='my_model', save_checkpoints=True,\n","#     force_reset=True,\n","#     use_reversible_instance_norm=True,\n","#     **generate_torch_kwargs()\n","# )\n","\n","# # model.trainer_params[\"enable_progress_bar\"] = False\n","# model.fit(train_y,train_lag,train_fu,val_y,val_lag,val_fu)\n","# print(glob.glob('/kaggle/working/*/*/*/*'))\n","# # model.fit(nom_y,past_covariates=nom_lag,future_covariates=nom_fu)\n","# best_model = model.load_from_checkpoint(model_name='my_model', best=True)\n","# pred_list = scaler_y.inverse_transform(best_model.predict(n=2, series=train_y, past_covariates=train_lag, future_covariates=train_fu))\n","# total=concatenate(pred_list,axis=1).pd_dataframe()\n","# total['PC10']=total.sum(axis=1)\n","# total"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a156b3f0-ec5e-4cb2-a19b-5ee6eaa325c4","_uuid":"543509a4-286c-4998-a233-9abd21c22980","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["# best_model = model.load_from_checkpoint(model_name='my_model', best=False)\n","# pred_list = scaler_y.inverse_transform(best_model.predict(n=2, series=train_y, past_covariates=train_lag, future_covariates=train_fu))\n","# total=concatenate(pred_list,axis=1).pd_dataframe()\n","# total['PC10']=total.sum(axis=1)\n","# total"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c9bb74fe-5109-492e-8d96-8c19d4c217cd","_uuid":"5327ad22-2fce-4a8d-acbd-72806fb11ea9","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["from lightning.pytorch import LightningModule\n","from lightning.pytorch import Trainer\n","from lightning.pytorch import Callback\n","import optuna\n","\n","class PyTorchLightningPruningCallback(Callback):\n","    \"\"\"PyTorch Lightning callback to prune unpromising trials.\n","    See `the example <https://github.com/optuna/optuna-examples/blob/\n","    main/pytorch/pytorch_lightning_simple.py>`__\n","    if you want to add a pruning callback which observes accuracy.\n","    Args:\n","        trial:\n","            A :class:`~optuna.trial.Trial` corresponding to the current evaluation of the\n","            objective function.\n","        monitor:\n","            An evaluation metric for pruning, e.g., ``val_loss`` or\n","            ``val_acc``. The metrics are obtained from the returned dictionaries from e.g.\n","            ``pytorch_lightning.LightningModule.training_step`` or\n","            ``pytorch_lightning.LightningModule.validation_epoch_end`` and the names thus depend on\n","            how this dictionary is formatted.\n","    \"\"\"\n","\n","    def __init__(self, trial: optuna.trial.Trial, monitor: str) -> None:\n","        super().__init__()\n","\n","        self._trial = trial\n","        self.monitor = monitor\n","        self._best_score = None\n","\n","    def on_validation_end(self, trainer: Trainer, pl_module: LightningModule) -> None:\n","        # When the trainer calls `on_validation_end` for sanity check,\n","        # do not call `trial.report` to avoid calling `trial.report` multiple times\n","        # at epoch 0. The related page is\n","        # https://github.com/PyTorchLightning/pytorch-lightning/issues/1391.\n","        if trainer.sanity_checking:\n","            return\n","\n","        epoch = pl_module.current_epoch\n","\n","        current_score = trainer.callback_metrics.get(self.monitor)\n","        if current_score is None:\n","            message = (\n","                \"The metric '{}' is not in the evaluation logs for pruning. \"\n","                \"Please make sure you set the correct metric name.\".format(self.monitor)\n","            )\n","            warnings.warn(message)\n","            return\n","        if self._best_score is None or current_score < self._best_score:\n","            self._best_score = current_score\n","            trainer.save_checkpoint(\"best_checkpoint.ckpt\")\n","            \n","        self._trial.report(current_score, step=epoch)\n","        if self._trial.should_prune() and epoch>0:\n","            message = \"Trial was pruned at epoch {}.\".format(epoch)\n","            raise optuna.TrialPruned(message)\n","    def on_train_end(self, trainer, pl_module):\n","        print(f\"epoch {pl_module.current_epoch}\",end=\" \")"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"37f410d1-63d3-43db-a6ff-92359664f2db","_uuid":"087b098b-bfee-4074-a5ec-10f24c4fb2e3","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["import numpy as np\n","from lightning.pytorch.callbacks import EarlyStopping\n","import optuna\n","# from optuna.integration import PyTorchLightningPruningCallback\n","from darts.metrics import smape\n","\n","back_step=2\n","n_step=2\n","len_val=4\n","input_chunk_length=25\n","\n","train_y  =[i[:-n_step-back_step-len_val+len_val] for i in nom_y]\n","train_lag=[i[:-n_step-back_step-len_val+len_val] for i in nom_lag]\n","train_fu =[i[:-back_step-len_val+len_val] for i in nom_fu] if back_step>0 else [i for i in nom_fu]\n","\n","val_y    =[i[-len_val-input_chunk_length-back_step:-n_step-back_step] for i in nom_y]\n","val_lag  =[i[-len_val-input_chunk_length-back_step:-n_step-back_step] for i in nom_lag]\n","val_fu   =[i[-len_val-input_chunk_length-back_step:-back_step] for i in nom_fu] \\\n","            if back_step>0 else [i[-len_val-input_chunk_length:] for i in nom_fu]\n","\n","test_y  =[i[:-n_step-back_step] for i in nom_y]\n","test_lag=[i[:-n_step-back_step] for i in nom_lag]\n","test_fu =[i[:-back_step] for i in nom_fu] if back_step>0 else [i for i in nom_fu]\n","\n","val_metric=[i[-n_step-back_step:-back_step] for i in nom_y] \\\n","            if back_step>0 else [i[-n_step:] for i in nom_y]\n","\n","# define objective function\n","def objective(trial):\n","    # select input and output chunk lengths\n","    n_epochs = trial.suggest_int(\"n_epochs\", 10, 40)\n","\n","    # Other hyperparameters\n","#     dropout = trial.suggest_float(\"dropout\", 0.1, 0.2)\n","    lr = trial.suggest_float(\"lr\", 5e-5, 1e-3, log=True)\n","\n","    # throughout training we'll monitor the validation loss for both pruning and early stopping\n","    pruner = PyTorchLightningPruningCallback(trial, monitor=\"val_loss\")\n","    early_stopper = EarlyStopping(\"val_loss\", min_delta=0.0001, patience=8, verbose=True)\n","\n","    # reproducibility\n","    torch.manual_seed(42)\n","\n","    # build the TCN model\n","    model = TiDEModel(\n","        input_chunk_length=input_chunk_length,\n","        output_chunk_length=n_step,\n","        n_epochs=36,\n","        num_encoder_layers=5,\n","        num_decoder_layers=5,\n","        decoder_output_dim=32,\n","        random_state=20,\n","        batch_size=4,\n","        dropout=0.2,\n","        activation=SwiGLU,\n","        optimizer_kwargs={\"lr\": lr},\n","        model_name='my_model', save_checkpoints=True,\n","        force_reset=True,\n","        use_reversible_instance_norm=True,\n","        pl_trainer_kwargs= {\n","            \"accelerator\": \"cpu\",\n","            \"callbacks\": [TFMProgressBar(enable_train_bar_only=True,refresh_rate=50,)],\n","            \"limit_train_batches\":0.2,\n","        }\n","    )\n","\n","\n","    # when validating during training, we can use a slightly longer validation\n","    # set which also contains the first input_chunk_length time steps\n","    # train the model\n","    \n","    model.fit(train_y,train_lag,train_fu,val_y,val_lag,val_fu,verbose=True)\n","\n","    # reload best model over course of training\n","#     model = TiDEModel.load_from_checkpoint(model_name='my_model')\n","\n","    # Evaluate how good it is on the validation set, using sMAPE\n","    preds = model.predict(n=2, series=train_y, past_covariates=train_lag, future_covariates=train_fu)\n","    smapes = smape(val_metric, preds, n_jobs=-1)\n","    smape_val = np.mean(smapes)\n","    \n","#     ipdb.set_trace()\n","    \n","    return smape_val if smape_val != np.nan else float(\"inf\")\n","\n","# for convenience, print some optimization trials information\n","def print_callback(study, trial):\n","    trial_params = {k: format(v, '.4e') for k, v in trial.params.items()}\n","    study_best_trial_params={k: format(v, '.4e') for k, v in study.best_trial.params.items()}\n","    print(f\"Current value: {trial.value:.5e},params: {trial_params}\")\n","    print(f\"Best value: {study.best_value:.5e},params: {study_best_trial_params}\")\n","\n","# optimize hyperparameters by minimizing the sMAPE on the validation set\n","if __name__ == \"__main__\":\n","    study = optuna.create_study(direction=\"minimize\")\n","    study.optimize(objective, n_trials=15, callbacks=[print_callback])"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"032ba919-548c-4ac3-bcf8-b038c9c0e1ce","_uuid":"15f461d4-d057-4e0c-80fc-137b91c8050e","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["# import numpy as np\n","# import torch\n","# from pytorch_lightning.callbacks import EarlyStopping\n","# from sklearn.preprocessing import MaxAbsScaler\n","\n","# from darts.dataprocessing.transformers import Scaler\n","# from darts.datasets import AirPassengersDataset\n","# from darts.metrics import smape\n","# from darts.models import TCNModel\n","# from darts.utils.likelihood_models import GaussianLikelihood\n","\n","# # load data\n","# series = AirPassengersDataset().load().astype(np.float32)\n","\n","# # split in train / validation (note: in practice we would also need a test set)\n","# VAL_LEN = 36\n","# train, val = series[:-VAL_LEN], series[-VAL_LEN:]\n","\n","# # scale\n","# scaler = Scaler(MaxAbsScaler())\n","# train = scaler.fit_transform(train)\n","# val = scaler.transform(val)\n","\n","# # define objective function\n","# def objective(trial):\n","#     # select input and output chunk lengths\n","#     in_len = trial.suggest_int(\"in_len\", 12, 36)\n","#     out_len = trial.suggest_int(\"out_len\", 1, in_len-1)\n","\n","#     # Other hyperparameters\n","#     kernel_size = trial.suggest_int(\"kernel_size\", 2, 5)\n","#     num_filters = trial.suggest_int(\"num_filters\", 1, 5)\n","#     weight_norm = trial.suggest_categorical(\"weight_norm\", [False, True])\n","#     dilation_base = trial.suggest_int(\"dilation_base\", 2, 4)\n","#     dropout = trial.suggest_float(\"dropout\", 0.0, 0.4)\n","#     lr = trial.suggest_float(\"lr\", 5e-5, 1e-3, log=True)\n","#     include_year = trial.suggest_categorical(\"year\", [False, True])\n","\n","#     # throughout training we'll monitor the validation loss for both pruning and early stopping\n","#     pruner = PyTorchLightningPruningCallback(trial, monitor=\"val_loss\")\n","#     early_stopper = EarlyStopping(\"val_loss\", min_delta=0.001, patience=3, verbose=True)\n","#     callbacks = [pruner, early_stopper]\n","\n","#     # detect if a GPU is available\n","#     if torch.cuda.is_available():\n","#         num_workers = 4\n","#     else:\n","#         num_workers = 0\n","\n","#     pl_trainer_kwargs = {\n","#         \"accelerator\": \"auto\",\n","#         \"callbacks\": callbacks,\n","#     }\n","\n","#     # optionally also add the (scaled) year value as a past covariate\n","#     if include_year:\n","#         encoders = {\"datetime_attribute\": {\"past\": [\"year\"]},\n","#                     \"transformer\": Scaler()}\n","#     else:\n","#         encoders = None\n","\n","#     # reproducibility\n","#     torch.manual_seed(42)\n","\n","#     # build the TCN model\n","#     model = TCNModel(\n","#         input_chunk_length=in_len,\n","#         output_chunk_length=out_len,\n","#         batch_size=32,\n","#         n_epochs=100,\n","#         nr_epochs_val_period=1,\n","#         kernel_size=kernel_size,\n","#         num_filters=num_filters,\n","#         weight_norm=weight_norm,\n","#         dilation_base=dilation_base,\n","#         dropout=dropout,\n","#         optimizer_kwargs={\"lr\": lr},\n","#         add_encoders=encoders,\n","#         likelihood=GaussianLikelihood(),\n","#         pl_trainer_kwargs=pl_trainer_kwargs,\n","#         model_name=\"tcn_model\",\n","#         force_reset=True,\n","#         save_checkpoints=True,\n","#     )\n","\n","\n","#     # when validating during training, we can use a slightly longer validation\n","#     # set which also contains the first input_chunk_length time steps\n","#     model_val_set = scaler.transform(series[-(VAL_LEN + in_len) :])\n","\n","#     # train the model\n","#     model.fit(\n","#         series=train,\n","#         val_series=model_val_set,\n","#         num_loader_workers=num_workers,\n","#     )\n","\n","#     # reload best model over course of training\n","#     model = TCNModel.load_from_checkpoint(\"tcn_model\")\n","\n","#     # Evaluate how good it is on the validation set, using sMAPE\n","#     preds = model.predict(series=train, n=VAL_LEN)\n","#     smapes = smape(val, preds, n_jobs=-1, verbose=True)\n","#     smape_val = np.mean(smapes)\n","    \n","#     return smape_val if smape_val != np.nan else float(\"inf\")\n","\n","\n","# # for convenience, print some optimization trials information\n","# def print_callback(study, trial):\n","#     print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n","#     print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")\n","\n","\n","# # optimize hyperparameters by minimizing the sMAPE on the validation set\n","# if __name__ == \"__main__\":\n","#     study = optuna.create_study(direction=\"minimize\")\n","#     study.optimize(objective, n_trials=100, callbacks=[print_callback])"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8f1cf3c6-9ddc-4e50-b67e-22fdb3a1a2b8","_uuid":"68dd5688-e4fe-47e3-bbe8-ae3f146d090a","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["# pred_list = model_air_milk.predict(n=36, series=[train_air, train_milk])\n","# for series, label in zip(pred_list, [\"air passengers\", \"milk production\"]):\n","#     series.plot(label=f\"forecast {label}\")\n","# plt.legend()"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a43ad26d-ed62-46cb-896a-95760f9412a9","_uuid":"b0ce5ebd-bee0-491f-b1b6-c16e86907566","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["# # generate an DataFrame example\n","# df = pd.DataFrame(\n","#     data={\n","#         \"dates\": [\n","#             \"2020-01-01\",\n","#             \"2020-01-02\",\n","#             \"2020-01-03\",\n","#             \"2020-01-01\",\n","#             \"2020-01-02\",\n","#             \"2020-01-03\",\n","#         ],\n","#         \"comp1\": np.random.random((6,)),\n","#         \"comp2\": np.random.random((6,)),\n","#         \"comp3\": np.random.random((6,)),\n","#         \"ID\": [\"SERIES1\", \"SERIES1\", \"SERIES1\", \"SERIES2\", \"SERIES2\", \"SERIES2\"],\n","#         \"var1\": [0.5, 0.5, 0.5, 0.75, 0.75, 0.75],\n","#     }\n","# )\n","# df"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5fa1e5fe-fee9-40c8-8394-22c22a7f0f7b","_uuid":"a8720651-542b-4a41-9758-8905169da8fb","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"17e83f74-36ed-4e84-b535-d6b3ec56ec38","_uuid":"f0e17088-18c6-4093-9639-79913b5c13a7","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["# series_multi = TimeSeries.from_group_dataframe(\n","#     df,\n","#     time_col=\"dates\",\n","#     group_cols=\"ID\",  # individual time series are extracted by grouping `df` by `group_cols`\n","#     static_cols=[\n","#         \"var1\"\n","#     ],  # also extract these additional columns as static covariates (without grouping)\n","#     value_cols=[\n","#         \"comp1\",\n","#         \"comp2\",\n","#         \"comp3\",\n","#     ],  # optionally, specify the time varying columns\n","# )\n","\n","# print(f\"\\n{len(series_multi)} series were extracted from the input DataFrame\")\n","# for i, ts in enumerate(series_multi):\n","#     print(f\"Static covariates of series {i}\")\n","#     print(ts.static_covariates)\n","# #     ts[\"comp1\"].plot(label=f\"comp1_series_{i}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b5f80243-a75a-472b-9c3f-22524ea4c473","_uuid":"8c7e2919-7974-491a-9ff3-191c1c99f797","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["# from darts.dataprocessing.transformers import StaticCovariatesTransformer\n","\n","# transformer = StaticCovariatesTransformer()\n","# series_transformed = transformer.fit_transform(series_multi)\n","\n","# for i, (ts, ts_scaled) in enumerate(zip(series_multi, series_transformed)):\n","#     print(f\"Original series {i}\")\n","#     print(ts.static_covariates)\n","#     print(f\"Transformed series {i}\")\n","#     print(ts_scaled.static_covariates)\n","#     print(\"\")"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e4e612fb-9877-4561-97d1-69cea9f330a6","_uuid":"6604ce34-8bec-44a8-a8d7-5f1925503e1d","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["# fu=df[df['ds']>='2024-01-01']\n","# fu.loc[:,'y']=None\n","# fu.loc[:,'DAU_NGUON_NHAN']=None\n","# fu.loc[:,'ds']=fu['ds']+pd.DateOffset(months=+2)\n","# # fu.loc[:,'NAM']=fu['ds'].dt.year\n","# # fu.loc[:,'THANG']=fu['ds'].dt.month\n","# fu.loc[:,'NUM_DAY_OF_MONTH']=fu['ds'].dt.days_in_month\n","# fu\n","# fu=pd.concat([df,fu])\n","# fu"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"eafa90df-983a-4aeb-9039-47413abbe2f7","_uuid":"12e8173d-8896-4b06-bd6f-0206e348396a","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["# from datetime import date \n","# import holidays \n","# import pandas as pd\n","\n","# # Select country   \n","# # Print all the holidays in Vietnam in year 2022 \n","# holidays_list = [(date, name) for date, name in holidays.Vietnam(years = [2018,2019,2020,2021,2022,2023,2024]).items()]\n","\n","# # Convert list to DataFrame\n","# df = pd.DataFrame(holidays_list, columns=['Date', 'Holiday'])\n","\n","# # Print DataFrame\n","# df.to_csv('ngay_le.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f6060398-c2ed-4e17-bdd4-3710d4154f96","_uuid":"49338940-cd09-42b1-bb2b-d9bbd682f473","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["# \"\"\"\n","# Optuna example that optimizes multi-layer perceptrons using PyTorch Lightning.\n","\n","# In this example, we optimize the validation accuracy of fashion product recognition using\n","# PyTorch Lightning, and FashionMNIST. We optimize the neural network architecture. As it is too time\n","# consuming to use the whole FashionMNIST dataset, we here use a small subset of it.\n","\n","# You can run this example as follows, pruning can be turned on and off with the `--pruning`\n","# argument.\n","#     $ python pytorch_lightning_simple.py [--pruning]\n","\n","# \"\"\"\n","\n","# import argparse\n","# import os\n","# from typing import List\n","# from typing import Optional\n","\n","# import lightning.pytorch as pl\n","# import optuna\n","# from optuna.integration import PyTorchLightningPruningCallback\n","# from packaging import version\n","# import torch\n","# from torch import nn\n","# from torch import optim\n","# import torch.nn.functional as F\n","# from torch.utils.data import DataLoader\n","# from torch.utils.data import random_split\n","# from torchvision import datasets\n","# from torchvision import transforms\n","\n","\n","# if version.parse(pl.__version__) < version.parse(\"1.6.0\"):\n","#     raise RuntimeError(\"PyTorch Lightning>=1.6.0 is required for this example.\")\n","\n","# PERCENT_VALID_EXAMPLES = 0.1\n","# BATCHSIZE = 128\n","# CLASSES = 10\n","# EPOCHS = 10\n","# DIR = os.getcwd()\n","\n","\n","# class Net(nn.Module):\n","#     def __init__(self, dropout: float, output_dims: List[int]) -> None:\n","#         super().__init__()\n","#         layers: List[nn.Module] = []\n","\n","#         input_dim: int = 28 * 28\n","#         for output_dim in output_dims:\n","#             layers.append(nn.Linear(input_dim, output_dim))\n","#             layers.append(nn.ReLU())\n","#             layers.append(nn.Dropout(dropout))\n","#             input_dim = output_dim\n","\n","#         layers.append(nn.Linear(input_dim, CLASSES))\n","\n","#         self.layers = nn.Sequential(*layers)\n","\n","#     def forward(self, data: torch.Tensor) -> torch.Tensor:\n","#         logits = self.layers(data)\n","#         return F.log_softmax(logits, dim=1)\n","\n","\n","# class LightningNet(pl.LightningModule):\n","#     def __init__(self, dropout: float, output_dims: List[int]) -> None:\n","#         super().__init__()\n","#         self.model = Net(dropout, output_dims)\n","\n","#     def forward(self, data: torch.Tensor) -> torch.Tensor:\n","#         return self.model(data.view(-1, 28 * 28))\n","\n","#     def training_step(self, batch: List[torch.Tensor], batch_idx: int) -> torch.Tensor:\n","#         data, target = batch\n","#         output = self(data)\n","#         return F.nll_loss(output, target)\n","\n","#     def validation_step(self, batch: List[torch.Tensor], batch_idx: int) -> None:\n","#         data, target = batch\n","#         output = self(data)\n","#         pred = output.argmax(dim=1, keepdim=True)\n","#         accuracy = pred.eq(target.view_as(pred)).float().mean()\n","#         self.log(\"val_acc\", accuracy)\n","#         self.log(\"hp_metric\", accuracy, on_step=False, on_epoch=True)\n","\n","#     def configure_optimizers(self) -> optim.Optimizer:\n","#         return optim.Adam(self.model.parameters())\n","\n","\n","# class FashionMNISTDataModule(pl.LightningDataModule):\n","#     def __init__(self, data_dir: str, batch_size: int):\n","#         super().__init__()\n","#         self.data_dir = data_dir\n","#         self.batch_size = batch_size\n","\n","#     def setup(self, stage: Optional[str] = None) -> None:\n","#         self.mnist_test = datasets.FashionMNIST(\n","#             self.data_dir, train=False, download=True, transform=transforms.ToTensor()\n","#         )\n","#         mnist_full = datasets.FashionMNIST(\n","#             self.data_dir, train=True, download=True, transform=transforms.ToTensor()\n","#         )\n","#         self.mnist_train, self.mnist_val = random_split(mnist_full, [55000, 5000])\n","\n","#     def train_dataloader(self) -> DataLoader:\n","#         return DataLoader(\n","#             self.mnist_train, batch_size=self.batch_size, shuffle=True, pin_memory=True\n","#         )\n","\n","#     def val_dataloader(self) -> DataLoader:\n","#         return DataLoader(\n","#             self.mnist_val, batch_size=self.batch_size, shuffle=False, pin_memory=True\n","#         )\n","\n","#     def test_dataloader(self) -> DataLoader:\n","#         return DataLoader(\n","#             self.mnist_test, batch_size=self.batch_size, shuffle=False, pin_memory=True\n","#         )\n","\n","\n","# def objective(trial: optuna.trial.Trial) -> float:\n","#     # We optimize the number of layers, hidden units in each layer and dropouts.\n","#     n_layers = trial.suggest_int(\"n_layers\", 1, 3)\n","#     dropout = trial.suggest_float(\"dropout\", 0.2, 0.5)\n","#     output_dims = [\n","#         trial.suggest_int(\"n_units_l{}\".format(i), 4, 128, log=True) for i in range(n_layers)\n","#     ]\n","\n","#     model = LightningNet(dropout, output_dims)\n","#     datamodule = FashionMNISTDataModule(data_dir=DIR, batch_size=BATCHSIZE)\n","\n","#     trainer = pl.Trainer(\n","#         logger=True,\n","#         limit_val_batches=PERCENT_VALID_EXAMPLES,\n","#         enable_checkpointing=False,\n","#         max_epochs=EPOCHS,\n","#         accelerator=\"auto\",\n","#         devices=1,\n","#         callbacks=[PyTorchLightningPruningCallback(trial, monitor=\"val_acc\")],\n","#     )\n","#     hyperparameters = dict(n_layers=n_layers, dropout=dropout, output_dims=output_dims)\n","#     trainer.logger.log_hyperparams(hyperparameters)\n","#     trainer.fit(model, datamodule=datamodule)\n","\n","#     return trainer.callback_metrics[\"val_acc\"].item()\n","\n","\n","# if __name__ == \"__main__\":\n","\n","#     pruner = optuna.pruners.MedianPruner() \n","\n","#     study = optuna.create_study(direction=\"maximize\", pruner=pruner)\n","#     study.optimize(objective, n_trials=100, timeout=600)\n","\n","#     print(\"Number of finished trials: {}\".format(len(study.trials)))\n","\n","#     print(\"Best trial:\")\n","#     trial = study.best_trial\n","\n","#     print(\"  Value: {}\".format(trial.value))\n","\n","#     print(\"  Params: \")\n","#     for key, value in trial.params.items():\n","#         print(\"    {}: {}\".format(key, value))"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6dda0a69-96e4-4095-85a1-74c77e7edf9c","_uuid":"a144765c-94f5-44ac-93c3-03347ba60489","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["# from pytorch_lightning import LightningModule\n","# from pytorch_lightning import Trainer\n","# from pytorch_lightning.callbacks import Callback\n","# import optuna\n","\n","# class PyTorchLightningPruningCallback(Callback):\n","#     \"\"\"PyTorch Lightning callback to prune unpromising trials.\n","#     See `the example <https://github.com/optuna/optuna-examples/blob/\n","#     main/pytorch/pytorch_lightning_simple.py>`__\n","#     if you want to add a pruning callback which observes accuracy.\n","#     Args:\n","#         trial:\n","#             A :class:`~optuna.trial.Trial` corresponding to the current evaluation of the\n","#             objective function.\n","#         monitor:\n","#             An evaluation metric for pruning, e.g., ``val_loss`` or\n","#             ``val_acc``. The metrics are obtained from the returned dictionaries from e.g.\n","#             ``pytorch_lightning.LightningModule.training_step`` or\n","#             ``pytorch_lightning.LightningModule.validation_epoch_end`` and the names thus depend on\n","#             how this dictionary is formatted.\n","#     \"\"\"\n","\n","#     def __init__(self, trial: optuna.trial.Trial, monitor: str) -> None:\n","#         super().__init__()\n","\n","#         self._trial = trial\n","#         self.monitor = monitor\n","\n","#     def on_validation_end(self, trainer: Trainer, pl_module: LightningModule) -> None:\n","#         # When the trainer calls `on_validation_end` for sanity check,\n","#         # do not call `trial.report` to avoid calling `trial.report` multiple times\n","#         # at epoch 0. The related page is\n","#         # https://github.com/PyTorchLightning/pytorch-lightning/issues/1391.\n","#         if trainer.sanity_checking:\n","#             return\n","\n","#         epoch = pl_module.current_epoch\n","\n","#         current_score = trainer.callback_metrics.get(self.monitor)\n","#         if current_score is None:\n","#             message = (\n","#                 \"The metric '{}' is not in the evaluation logs for pruning. \"\n","#                 \"Please make sure you set the correct metric name.\".format(self.monitor)\n","#             )\n","#             warnings.warn(message)\n","#             return\n","\n","#         self._trial.report(current_score, step=epoch)\n","#         if self._trial.should_prune():\n","#             message = \"Trial was pruned at epoch {}.\".format(epoch)\n","#             raise optuna.TrialPruned(message)\n","#     def on_train_end(self, trainer, pl_module):\n","#         print(pl_module.current_epoch)"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4647668,"sourceId":8608396,"sourceType":"datasetVersion"}],"dockerImageVersionId":30673,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"}},"nbformat":4,"nbformat_minor":4}
