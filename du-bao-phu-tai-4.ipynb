{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-05-23T16:16:17.142846Z",
     "iopub.status.busy": "2024-05-23T16:16:17.142370Z",
     "iopub.status.idle": "2024-05-23T16:17:43.001197Z",
     "shell.execute_reply": "2024-05-23T16:17:42.999408Z",
     "shell.execute_reply.started": "2024-05-23T16:16:17.142807Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# try:\n",
    "#     from darts import TimeSeries\n",
    "#     import ipdb\n",
    "# except:\n",
    "# #     !pip install -q darts\n",
    "#     %pip install -q git+https://github.com/thucpc/darts_thuc.git\n",
    "#     %pip install -q ipdb\n",
    "#     %pip install -q lightning\n",
    "# #     !pip install -q optuna-integration"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-23T16:21:29.173641Z",
     "iopub.status.busy": "2024-05-23T16:21:29.173117Z",
     "iopub.status.idle": "2024-05-23T16:21:44.324713Z",
     "shell.execute_reply": "2024-05-23T16:21:44.323839Z",
     "shell.execute_reply.started": "2024-05-23T16:21:29.173604Z"
    },
    "metadata": {},
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-29T08:15:57.520437Z",
     "start_time": "2024-05-29T08:15:52.219680Z"
    }
   },
   "source": [
    "import ipdb\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchmetrics\n",
    "\n",
    "\n",
    "from darts import TimeSeries, concatenate\n",
    "from darts.utils.callbacks import TFMProgressBar\n",
    "\n",
    "# from darts.models.components.glu_variants import SwiGLU\n",
    "from darts.models import TiDEModel,TransformerModel,TFTModel\n",
    "from darts.models.forecasting.transformer_invert import iTransformerModel\n",
    "from darts.metrics import mape, smape, mae\n",
    "from darts.dataprocessing.transformers import Scaler,StaticCovariatesTransformer\n",
    "from darts.utils.timeseries_generation import datetime_attribute_timeseries\n",
    "\n",
    "import logging\n",
    "\n",
    "logging.disable(logging.CRITICAL)\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# for reproducibility\n",
    "torch.manual_seed(1)\n",
    "np.random.seed(1)\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Delll\\AppData\\Roaming\\Python\\Python312\\site-packages\\statsforecast\\core.py:27: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-23T16:35:27.311866Z",
     "iopub.status.busy": "2024-05-23T16:35:27.311470Z",
     "iopub.status.idle": "2024-05-23T16:35:27.332625Z",
     "shell.execute_reply": "2024-05-23T16:35:27.331502Z",
     "shell.execute_reply.started": "2024-05-23T16:35:27.311826Z"
    },
    "metadata": {},
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-29T08:16:04.034722Z",
     "start_time": "2024-05-29T08:16:04.025232Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class SwiGLU(nn.Module):\n",
    "    def __init__(self, input_dim=None, d_model=None, beta=1.0):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        if self.input_dim is not None:\n",
    "            self.linear1 = nn.Linear(self.input_dim, self.input_dim)\n",
    "            self.linear2 = nn.Linear(self.input_dim, self.input_dim)\n",
    "        else:\n",
    "            self.linear1 = None\n",
    "            self.linear2 = None\n",
    "        self.beta = nn.Parameter(torch.tensor(beta))  # Biến beta thành tham số có thể học\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.linear1 is None or self.linear2 is None:\n",
    "            self.linear1 = nn.Linear(x.size(-1), x.size(-1))\n",
    "            self.linear2 = nn.Linear(x.size(-1), x.size(-1))\n",
    "        return self.swish(self.linear1(x)) * self.linear2(x)\n",
    "\n",
    "    def swish(self, x):\n",
    "        return x * torch.sigmoid(self.beta * x)\n",
    "\n",
    "class LogCoshLoss(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, y_t, y_prime_t):\n",
    "        ey_t = y_t - y_prime_t\n",
    "        return torch.mean(torch.log(torch.cosh(ey_t + 1e-12)))\n",
    "    \n",
    "class CustomLoss(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, input_value, target_value):\n",
    "        error = target_value - input_value\n",
    "        A=torch.sum((target_value**2)*(error**2))\n",
    "        B=torch.sum(target_value**2)\n",
    "        loss = A/B\n",
    "        return loss\n",
    "\n",
    "class CustomLoss1(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, input_value, target_value):\n",
    "        error = target_value - input_value\n",
    "        loss = torch.sum(target_value*(error**2))/torch.sum(target_value)\n",
    "        return loss\n",
    "\n",
    "class CustomLoss2(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, y_t, y_prime_t):\n",
    "        ey_t = y_t - y_prime_t\n",
    "        loss=torch.sum(y_prime_t**2*torch.log(torch.cosh(ey_t**2 + 1e-12)))\n",
    "        return loss/torch.sum(y_prime_t**2)\n"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# def _mean_squared_error_compute(sum_squared_error: Tensor, num_obs: Union[int, Tensor], squared: bool = True) -> Tensor:\n",
    "#     \"\"\"Compute Mean Squared Error.\n",
    "\n",
    "#     Args:\n",
    "#         sum_squared_error: Sum of square of errors over all observations\n",
    "#         num_obs: Number of predictions or observations\n",
    "#         squared: Returns RMSE value if set to False.\n",
    "\n",
    "#     Example:\n",
    "#         >>> preds = torch.tensor([0., 1, 2, 3])\n",
    "#         >>> target = torch.tensor([0., 1, 2, 2])\n",
    "#         >>> sum_squared_error, num_obs = _mean_squared_error_update(preds, target, num_outputs=1)\n",
    "#         >>> _mean_squared_error_compute(sum_squared_error, num_obs)\n",
    "#         tensor(0.2500)\n",
    "\n",
    "#     \"\"\"\n",
    "#     return sum_squared_error / num_obs if squared else torch.sqrt(sum_squared_error / num_obs)\n",
    "\n",
    "# class MeanSquaredError(Metric):\n",
    "#     r\"\"\"Compute `mean squared error`_ (MSE).\n",
    "\n",
    "#     .. math:: \\text{MSE} = \\frac{1}{N}\\sum_i^N(y_i - \\hat{y_i})^2\n",
    "\n",
    "#     Where :math:`y` is a tensor of target values, and :math:`\\hat{y}` is a tensor of predictions.\n",
    "\n",
    "#     As input to ``forward`` and ``update`` the metric accepts the following input:\n",
    "\n",
    "#     - ``preds`` (:class:`~torch.Tensor`): Predictions from model\n",
    "#     - ``target`` (:class:`~torch.Tensor`): Ground truth values\n",
    "\n",
    "#     As output of ``forward`` and ``compute`` the metric returns the following output:\n",
    "\n",
    "#     - ``mean_squared_error`` (:class:`~torch.Tensor`): A tensor with the mean squared error\n",
    "\n",
    "#     Args:\n",
    "#         squared: If True returns MSE value, if False returns RMSE value.\n",
    "#         num_outputs: Number of outputs in multioutput setting\n",
    "#         kwargs: Additional keyword arguments, see :ref:`Metric kwargs` for more info.\n",
    "\n",
    "#     Example::\n",
    "#         Single output mse computation:\n",
    "\n",
    "#         >>> from torch import tensor\n",
    "#         >>> from torchmetrics.regression import MeanSquaredError\n",
    "#         >>> target = tensor([2.5, 5.0, 4.0, 8.0])\n",
    "#         >>> preds = tensor([3.0, 5.0, 2.5, 7.0])\n",
    "#         >>> mean_squared_error = MeanSquaredError()\n",
    "#         >>> mean_squared_error(preds, target)\n",
    "#         tensor(0.8750)\n",
    "\n",
    "#     Example::\n",
    "#         Multioutput mse computation:\n",
    "\n",
    "#         >>> from torch import tensor\n",
    "#         >>> from torchmetrics.regression import MeanSquaredError\n",
    "#         >>> target = tensor([[0.0, 0.0, 0.0], [0.0, 0.0, 0.0]])\n",
    "#         >>> preds = tensor([[1.0, 2.0, 3.0], [1.0, 2.0, 3.0]])\n",
    "#         >>> mean_squared_error = MeanSquaredError(num_outputs=3)\n",
    "#         >>> mean_squared_error(preds, target)\n",
    "#         tensor([1., 4., 9.])\n",
    "\n",
    "#     \"\"\"\n",
    "\n",
    "#     is_differentiable = True\n",
    "#     higher_is_better = False\n",
    "#     full_state_update = False\n",
    "#     plot_lower_bound: float = 0.0\n",
    "\n",
    "#     sum_squared_error: Tensor\n",
    "#     total: Tensor\n",
    "\n",
    "#     def __init__(\n",
    "#         self,\n",
    "#         squared: bool = True,\n",
    "#         num_outputs: int = 1,\n",
    "#         **kwargs: Any,\n",
    "#     ) -> None:\n",
    "#         super().__init__(**kwargs)\n",
    "\n",
    "#         if not isinstance(squared, bool):\n",
    "#             raise ValueError(f\"Expected argument `squared` to be a boolean but got {squared}\")\n",
    "#         self.squared = squared\n",
    "\n",
    "#         if not (isinstance(num_outputs, int) and num_outputs > 0):\n",
    "#             raise ValueError(f\"Expected num_outputs to be a positive integer but got {num_outputs}\")\n",
    "#         self.num_outputs = num_outputs\n",
    "\n",
    "#         self.add_state(\"sum_squared_error\", default=torch.zeros(num_outputs), dist_reduce_fx=\"sum\")\n",
    "#         self.add_state(\"total\", default=tensor(0), dist_reduce_fx=\"sum\")\n",
    "\n",
    "#     def update(self, preds: Tensor, target: Tensor) -> None:\n",
    "#         \"\"\"Update state with predictions and targets.\"\"\"\n",
    "#         sum_squared_error, num_obs = _mean_squared_error_update(preds, target, num_outputs=self.num_outputs)\n",
    "\n",
    "#         self.sum_squared_error += sum_squared_error\n",
    "#         self.total += num_obs\n",
    "\n",
    "#     def compute(self) -> Tensor:\n",
    "#         \"\"\"Compute mean squared error over state.\"\"\"\n",
    "#         return _mean_squared_error_compute(self.sum_squared_error, self.total, squared=self.squared)\n",
    "\n",
    "#     def plot(\n",
    "#         self, val: Optional[Union[Tensor, Sequence[Tensor]]] = None, ax: Optional[_AX_TYPE] = None\n",
    "#     ) -> _PLOT_OUT_TYPE:\n",
    "#         \"\"\"Plot a single or multiple values from the metric.\n",
    "\n",
    "#         Args:\n",
    "#             val: Either a single result from calling `metric.forward` or `metric.compute` or a list of these results.\n",
    "#                 If no value is provided, will automatically call `metric.compute` and plot that result.\n",
    "#             ax: An matplotlib axis object. If provided will add plot to that axis\n",
    "\n",
    "#         Returns:\n",
    "#             Figure and Axes object\n",
    "\n",
    "#         Raises:\n",
    "#             ModuleNotFoundError:\n",
    "#                 If `matplotlib` is not installed\n",
    "\n",
    "#         .. plot::\n",
    "#             :scale: 75\n",
    "\n",
    "#             >>> from torch import randn\n",
    "#             >>> # Example plotting a single value\n",
    "#             >>> from torchmetrics.regression import MeanSquaredError\n",
    "#             >>> metric = MeanSquaredError()\n",
    "#             >>> metric.update(randn(10,), randn(10,))\n",
    "#             >>> fig_, ax_ = metric.plot()\n",
    "\n",
    "#         .. plot::\n",
    "#             :scale: 75\n",
    "\n",
    "#             >>> from torch import randn\n",
    "#             >>> # Example plotting multiple values\n",
    "#             >>> from torchmetrics.regression import MeanSquaredError\n",
    "#             >>> metric = MeanSquaredError()\n",
    "#             >>> values = []\n",
    "#             >>> for _ in range(10):\n",
    "#             ...     values.append(metric(randn(10,), randn(10,)))\n",
    "#             >>> fig, ax = metric.plot(values)\n",
    "\n",
    "#         \"\"\"\n",
    "#         return self._plot(val, ax)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-23T16:21:53.480502Z",
     "iopub.status.busy": "2024-05-23T16:21:53.480203Z",
     "iopub.status.idle": "2024-05-23T16:21:53.491048Z",
     "shell.execute_reply": "2024-05-23T16:21:53.489951Z",
     "shell.execute_reply.started": "2024-05-23T16:21:53.480469Z"
    },
    "metadata": {},
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-29T08:16:07.771567Z",
     "start_time": "2024-05-29T08:16:07.759724Z"
    }
   },
   "source": [
    "list_y=['THUONG_PHAM_D1M']\n",
    "list_lag=['SO_LUONG_KH','SO_LUONG_KH_DMTMN','SAN_LUONG_DMTMN','CONG_SUAT_DMTMN']\n",
    "list_weather=['Average of temp','Min of tempmin','Max of tempmax','Average of dew','Average of precip','Average of humidity','Average of pressure','Average of windspeed','Average of solarradiation','Average of solarenergy']\n",
    "list_lag2=['NN_1110','NN_1120','NN_1200','NN_1300','NN_1400','NN_2100','NN_2101','NN_2102','NN_2103','NN_2104','NN_2105','NN_2201','NN_2202','NN_2203','NN_2204','NN_2205','NN_2206','NN_2207','NN_2208','NN_2209','NN_2210','NN_2211','NN_2212','NN_2213','NN_2214','NN_2215','NN_2216','NN_2217','NN_2218','NN_2219','NN_2221','NN_2222','NN_2223','NN_2301','NN_2302','NN_2303','NN_2400','NN_2410','NN_2420','NN_2430','NN_2500','NN_3100','NN_3101','NN_3102','NN_3200','NN_3210','NN_3220','NN_3230','NN_4100','NN_4300','NN_4400','NN_4401','NN_4402','NN_5000','NN_5100','NN_5101','NN_5102','NN_5103','NN_5104','NN_5200','NN_5301','NN_5302','NN_5400','NN_5401','NN_5402','NN_5403','NN_5404','NN_5500']\n",
    "list_lag3=['Holidays','Holidays_date','Holidays_numdays']\n",
    "list_lag=list_lag+list_lag2+list_lag3+list_weather\n",
    "list_fu=['NUM_DAY_OF_MONTH','Covid','Ukraine war']\n",
    "list_static=['LAT','LONG']\n",
    "# ,'Sum of precip'"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-23T16:21:56.092729Z",
     "iopub.status.busy": "2024-05-23T16:21:56.092413Z",
     "iopub.status.idle": "2024-05-23T16:21:59.790429Z",
     "shell.execute_reply": "2024-05-23T16:21:59.789337Z",
     "shell.execute_reply.started": "2024-05-23T16:21:56.092700Z"
    },
    "metadata": {},
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-29T08:16:13.390789Z",
     "start_time": "2024-05-29T08:16:11.627927Z"
    }
   },
   "source": [
    "df=pd.read_excel('San_luong_thuong_pham_dmtmn_theo_thang_02_05_2024.xlsx')\n",
    "df['ds'] = pd.PeriodIndex(year=df['NAM'], month=df['THANG'], freq='M')\n",
    "df['ds'] = df['ds'].dt.to_timestamp()\n",
    "df.drop(columns=['NAM_THANG','THUONG_PHAM_D1M_TB','THUONG_PHAM','THUONG_PHAM_TB','THUONG_PHAM_T1M','THUONG_PHAM_T1M_TB'],inplace=True)\n",
    "df.pivot(index='ds',columns='MA_DVIQLY',values='THUONG_PHAM_D1M')"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MA_DVIQLY     PC10AA   PC10BB   PC10CC   PC10DD    PC10EE   PC10FF   PC10GG  \\\n",
       "ds                                                                            \n",
       "2018-01-01  22780144  5591236  3631087  2147944   6765956  1925927  4200751   \n",
       "2018-02-01  20493846  5432752  3411785  2041699   7119443  1845737  3901336   \n",
       "2018-03-01  22984151  6000746  4024543  2351662   7674796  2060704  4096243   \n",
       "2018-04-01  22867098  6170370  4105717  2531835   6654484  2050945  4076103   \n",
       "2018-05-01  23109768  6605146  4258483  2764410   5523007  2189953  3951701   \n",
       "...              ...      ...      ...      ...       ...      ...      ...   \n",
       "2023-12-01  28036226  7040482  5456418  3299510   8774292  2466843  4989979   \n",
       "2024-01-01  29890345  7472128  6302058  3390923  10916321  2501838  5511449   \n",
       "2024-02-01  26789128  7166829  5681707  3585660  11324567  2683257  5235877   \n",
       "2024-03-01  31633176  8580047  6648549  4537247  12360759  2977369  5910902   \n",
       "2024-04-01  34563110  9287909  7123498  5033673  13290579  3014845  6727819   \n",
       "\n",
       "MA_DVIQLY     PC10HH   PC10II    PC10KK   PC10LL   PC10MM    PC10NN   PC10OO  \\\n",
       "ds                                                                             \n",
       "2018-01-01   5825367  4062065   7787595  1174865  4392775   7386961  2771960   \n",
       "2018-02-01   6540228  4279496   8333695  1054739  4251703   7839868  2590108   \n",
       "2018-03-01   6461873  4006350   7599260  1228859  4465837   8506157  2983940   \n",
       "2018-04-01   4961267  3108473   5564470  1261605  3904932   6895523  3041129   \n",
       "2018-05-01   4153447  2827978   4720504  1293530  3358560   5392399  3130344   \n",
       "...              ...      ...       ...      ...      ...       ...      ...   \n",
       "2023-12-01   6922220  4318844   8441099  1809034  5116342  11387319  4351927   \n",
       "2024-01-01   9436056  7241823  11305381  1856730  5822724  16669559  4607856   \n",
       "2024-02-01  10326069  6460412  11451349  1754988  6804869  15234754  4657306   \n",
       "2024-03-01  10803056  7311590  12887624  2108449  6910177  17774000  5537126   \n",
       "2024-04-01  10769671  7605021  12833665  2287721  6976832  19006172  5908724   \n",
       "\n",
       "MA_DVIQLY    PC10PP  \n",
       "ds                   \n",
       "2018-01-01  3632473  \n",
       "2018-02-01  3543659  \n",
       "2018-03-01  3870439  \n",
       "2018-04-01  3475606  \n",
       "2018-05-01  2951954  \n",
       "...             ...  \n",
       "2023-12-01  4519629  \n",
       "2024-01-01  5240909  \n",
       "2024-02-01  5228309  \n",
       "2024-03-01  5783013  \n",
       "2024-04-01  6379401  \n",
       "\n",
       "[76 rows x 15 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>MA_DVIQLY</th>\n",
       "      <th>PC10AA</th>\n",
       "      <th>PC10BB</th>\n",
       "      <th>PC10CC</th>\n",
       "      <th>PC10DD</th>\n",
       "      <th>PC10EE</th>\n",
       "      <th>PC10FF</th>\n",
       "      <th>PC10GG</th>\n",
       "      <th>PC10HH</th>\n",
       "      <th>PC10II</th>\n",
       "      <th>PC10KK</th>\n",
       "      <th>PC10LL</th>\n",
       "      <th>PC10MM</th>\n",
       "      <th>PC10NN</th>\n",
       "      <th>PC10OO</th>\n",
       "      <th>PC10PP</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ds</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-01</th>\n",
       "      <td>22780144</td>\n",
       "      <td>5591236</td>\n",
       "      <td>3631087</td>\n",
       "      <td>2147944</td>\n",
       "      <td>6765956</td>\n",
       "      <td>1925927</td>\n",
       "      <td>4200751</td>\n",
       "      <td>5825367</td>\n",
       "      <td>4062065</td>\n",
       "      <td>7787595</td>\n",
       "      <td>1174865</td>\n",
       "      <td>4392775</td>\n",
       "      <td>7386961</td>\n",
       "      <td>2771960</td>\n",
       "      <td>3632473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-01</th>\n",
       "      <td>20493846</td>\n",
       "      <td>5432752</td>\n",
       "      <td>3411785</td>\n",
       "      <td>2041699</td>\n",
       "      <td>7119443</td>\n",
       "      <td>1845737</td>\n",
       "      <td>3901336</td>\n",
       "      <td>6540228</td>\n",
       "      <td>4279496</td>\n",
       "      <td>8333695</td>\n",
       "      <td>1054739</td>\n",
       "      <td>4251703</td>\n",
       "      <td>7839868</td>\n",
       "      <td>2590108</td>\n",
       "      <td>3543659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-01</th>\n",
       "      <td>22984151</td>\n",
       "      <td>6000746</td>\n",
       "      <td>4024543</td>\n",
       "      <td>2351662</td>\n",
       "      <td>7674796</td>\n",
       "      <td>2060704</td>\n",
       "      <td>4096243</td>\n",
       "      <td>6461873</td>\n",
       "      <td>4006350</td>\n",
       "      <td>7599260</td>\n",
       "      <td>1228859</td>\n",
       "      <td>4465837</td>\n",
       "      <td>8506157</td>\n",
       "      <td>2983940</td>\n",
       "      <td>3870439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-01</th>\n",
       "      <td>22867098</td>\n",
       "      <td>6170370</td>\n",
       "      <td>4105717</td>\n",
       "      <td>2531835</td>\n",
       "      <td>6654484</td>\n",
       "      <td>2050945</td>\n",
       "      <td>4076103</td>\n",
       "      <td>4961267</td>\n",
       "      <td>3108473</td>\n",
       "      <td>5564470</td>\n",
       "      <td>1261605</td>\n",
       "      <td>3904932</td>\n",
       "      <td>6895523</td>\n",
       "      <td>3041129</td>\n",
       "      <td>3475606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-01</th>\n",
       "      <td>23109768</td>\n",
       "      <td>6605146</td>\n",
       "      <td>4258483</td>\n",
       "      <td>2764410</td>\n",
       "      <td>5523007</td>\n",
       "      <td>2189953</td>\n",
       "      <td>3951701</td>\n",
       "      <td>4153447</td>\n",
       "      <td>2827978</td>\n",
       "      <td>4720504</td>\n",
       "      <td>1293530</td>\n",
       "      <td>3358560</td>\n",
       "      <td>5392399</td>\n",
       "      <td>3130344</td>\n",
       "      <td>2951954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-01</th>\n",
       "      <td>28036226</td>\n",
       "      <td>7040482</td>\n",
       "      <td>5456418</td>\n",
       "      <td>3299510</td>\n",
       "      <td>8774292</td>\n",
       "      <td>2466843</td>\n",
       "      <td>4989979</td>\n",
       "      <td>6922220</td>\n",
       "      <td>4318844</td>\n",
       "      <td>8441099</td>\n",
       "      <td>1809034</td>\n",
       "      <td>5116342</td>\n",
       "      <td>11387319</td>\n",
       "      <td>4351927</td>\n",
       "      <td>4519629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-01</th>\n",
       "      <td>29890345</td>\n",
       "      <td>7472128</td>\n",
       "      <td>6302058</td>\n",
       "      <td>3390923</td>\n",
       "      <td>10916321</td>\n",
       "      <td>2501838</td>\n",
       "      <td>5511449</td>\n",
       "      <td>9436056</td>\n",
       "      <td>7241823</td>\n",
       "      <td>11305381</td>\n",
       "      <td>1856730</td>\n",
       "      <td>5822724</td>\n",
       "      <td>16669559</td>\n",
       "      <td>4607856</td>\n",
       "      <td>5240909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-01</th>\n",
       "      <td>26789128</td>\n",
       "      <td>7166829</td>\n",
       "      <td>5681707</td>\n",
       "      <td>3585660</td>\n",
       "      <td>11324567</td>\n",
       "      <td>2683257</td>\n",
       "      <td>5235877</td>\n",
       "      <td>10326069</td>\n",
       "      <td>6460412</td>\n",
       "      <td>11451349</td>\n",
       "      <td>1754988</td>\n",
       "      <td>6804869</td>\n",
       "      <td>15234754</td>\n",
       "      <td>4657306</td>\n",
       "      <td>5228309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-01</th>\n",
       "      <td>31633176</td>\n",
       "      <td>8580047</td>\n",
       "      <td>6648549</td>\n",
       "      <td>4537247</td>\n",
       "      <td>12360759</td>\n",
       "      <td>2977369</td>\n",
       "      <td>5910902</td>\n",
       "      <td>10803056</td>\n",
       "      <td>7311590</td>\n",
       "      <td>12887624</td>\n",
       "      <td>2108449</td>\n",
       "      <td>6910177</td>\n",
       "      <td>17774000</td>\n",
       "      <td>5537126</td>\n",
       "      <td>5783013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-04-01</th>\n",
       "      <td>34563110</td>\n",
       "      <td>9287909</td>\n",
       "      <td>7123498</td>\n",
       "      <td>5033673</td>\n",
       "      <td>13290579</td>\n",
       "      <td>3014845</td>\n",
       "      <td>6727819</td>\n",
       "      <td>10769671</td>\n",
       "      <td>7605021</td>\n",
       "      <td>12833665</td>\n",
       "      <td>2287721</td>\n",
       "      <td>6976832</td>\n",
       "      <td>19006172</td>\n",
       "      <td>5908724</td>\n",
       "      <td>6379401</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 15 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-23T16:22:04.564406Z",
     "iopub.status.busy": "2024-05-23T16:22:04.563252Z",
     "iopub.status.idle": "2024-05-23T16:22:04.588260Z",
     "shell.execute_reply": "2024-05-23T16:22:04.587393Z",
     "shell.execute_reply.started": "2024-05-23T16:22:04.564354Z"
    },
    "metadata": {},
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-29T08:16:21.511912Z",
     "start_time": "2024-05-29T08:16:21.498456Z"
    }
   },
   "source": [
    "dfp=df.pivot(index='ds',columns='MA_DVIQLY',values='THUONG_PHAM_D1M')\n",
    "dfp['total']=dfp.sum(axis=1)\n",
    "dfp.tail(4)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MA_DVIQLY     PC10AA   PC10BB   PC10CC   PC10DD    PC10EE   PC10FF   PC10GG  \\\n",
       "ds                                                                            \n",
       "2024-01-01  29890345  7472128  6302058  3390923  10916321  2501838  5511449   \n",
       "2024-02-01  26789128  7166829  5681707  3585660  11324567  2683257  5235877   \n",
       "2024-03-01  31633176  8580047  6648549  4537247  12360759  2977369  5910902   \n",
       "2024-04-01  34563110  9287909  7123498  5033673  13290579  3014845  6727819   \n",
       "\n",
       "MA_DVIQLY     PC10HH   PC10II    PC10KK   PC10LL   PC10MM    PC10NN   PC10OO  \\\n",
       "ds                                                                             \n",
       "2024-01-01   9436056  7241823  11305381  1856730  5822724  16669559  4607856   \n",
       "2024-02-01  10326069  6460412  11451349  1754988  6804869  15234754  4657306   \n",
       "2024-03-01  10803056  7311590  12887624  2108449  6910177  17774000  5537126   \n",
       "2024-04-01  10769671  7605021  12833665  2287721  6976832  19006172  5908724   \n",
       "\n",
       "MA_DVIQLY    PC10PP      total  \n",
       "ds                              \n",
       "2024-01-01  5240909  128166100  \n",
       "2024-02-01  5228309  124385081  \n",
       "2024-03-01  5783013  141763084  \n",
       "2024-04-01  6379401  150808640  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>MA_DVIQLY</th>\n",
       "      <th>PC10AA</th>\n",
       "      <th>PC10BB</th>\n",
       "      <th>PC10CC</th>\n",
       "      <th>PC10DD</th>\n",
       "      <th>PC10EE</th>\n",
       "      <th>PC10FF</th>\n",
       "      <th>PC10GG</th>\n",
       "      <th>PC10HH</th>\n",
       "      <th>PC10II</th>\n",
       "      <th>PC10KK</th>\n",
       "      <th>PC10LL</th>\n",
       "      <th>PC10MM</th>\n",
       "      <th>PC10NN</th>\n",
       "      <th>PC10OO</th>\n",
       "      <th>PC10PP</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ds</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-01-01</th>\n",
       "      <td>29890345</td>\n",
       "      <td>7472128</td>\n",
       "      <td>6302058</td>\n",
       "      <td>3390923</td>\n",
       "      <td>10916321</td>\n",
       "      <td>2501838</td>\n",
       "      <td>5511449</td>\n",
       "      <td>9436056</td>\n",
       "      <td>7241823</td>\n",
       "      <td>11305381</td>\n",
       "      <td>1856730</td>\n",
       "      <td>5822724</td>\n",
       "      <td>16669559</td>\n",
       "      <td>4607856</td>\n",
       "      <td>5240909</td>\n",
       "      <td>128166100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-01</th>\n",
       "      <td>26789128</td>\n",
       "      <td>7166829</td>\n",
       "      <td>5681707</td>\n",
       "      <td>3585660</td>\n",
       "      <td>11324567</td>\n",
       "      <td>2683257</td>\n",
       "      <td>5235877</td>\n",
       "      <td>10326069</td>\n",
       "      <td>6460412</td>\n",
       "      <td>11451349</td>\n",
       "      <td>1754988</td>\n",
       "      <td>6804869</td>\n",
       "      <td>15234754</td>\n",
       "      <td>4657306</td>\n",
       "      <td>5228309</td>\n",
       "      <td>124385081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-01</th>\n",
       "      <td>31633176</td>\n",
       "      <td>8580047</td>\n",
       "      <td>6648549</td>\n",
       "      <td>4537247</td>\n",
       "      <td>12360759</td>\n",
       "      <td>2977369</td>\n",
       "      <td>5910902</td>\n",
       "      <td>10803056</td>\n",
       "      <td>7311590</td>\n",
       "      <td>12887624</td>\n",
       "      <td>2108449</td>\n",
       "      <td>6910177</td>\n",
       "      <td>17774000</td>\n",
       "      <td>5537126</td>\n",
       "      <td>5783013</td>\n",
       "      <td>141763084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-04-01</th>\n",
       "      <td>34563110</td>\n",
       "      <td>9287909</td>\n",
       "      <td>7123498</td>\n",
       "      <td>5033673</td>\n",
       "      <td>13290579</td>\n",
       "      <td>3014845</td>\n",
       "      <td>6727819</td>\n",
       "      <td>10769671</td>\n",
       "      <td>7605021</td>\n",
       "      <td>12833665</td>\n",
       "      <td>2287721</td>\n",
       "      <td>6976832</td>\n",
       "      <td>19006172</td>\n",
       "      <td>5908724</td>\n",
       "      <td>6379401</td>\n",
       "      <td>150808640</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# dfp=df.pivot(index='ds',columns='MA_DVIQLY',values='Average of precip')\n",
    "# dfp['total']=dfp.sum(axis=1)\n",
    "# dfp.tail(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# df=df.loc[df['ds']<='2024-01-01']\n",
    "# fu=df[df['ds']>='2023-12-01']\n",
    "# fu.loc[:,list_y+list_lag]=None\n",
    "# fu.loc[:,'ds']=fu['ds']+pd.DateOffset(months=+2) #dataframe future 1 tháng\n",
    "# fu.loc[:,'NAM']=fu['ds'].dt.year\n",
    "# fu.loc[:,'THANG']=fu['ds'].dt.month\n",
    "# fu.loc[:,'NUM_DAY_OF_MONTH']=fu['ds'].dt.days_in_month\n",
    "# df=pd.concat([df,fu])\n",
    "# df.set_index('ds', inplace=True)\n",
    "# df.drop(columns='NUM_DAY_OF_MONTH.1',inplace=True)\n",
    "# df[df['MA_DVIQLY']=='PC10AA']"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-23T16:22:08.347809Z",
     "iopub.status.busy": "2024-05-23T16:22:08.346866Z",
     "iopub.status.idle": "2024-05-23T16:22:08.450484Z",
     "shell.execute_reply": "2024-05-23T16:22:08.449467Z",
     "shell.execute_reply.started": "2024-05-23T16:22:08.347766Z"
    },
    "metadata": {},
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-29T08:16:25.498132Z",
     "start_time": "2024-05-29T08:16:25.433652Z"
    }
   },
   "source": [
    "df=df.loc[df['ds']<='2024-04-01']\n",
    "fu=df[df['ds']>='2024-03-01']\n",
    "fu.loc[:,list_y+list_lag]=None\n",
    "fu.loc[:,'ds']=fu['ds']+pd.DateOffset(months=+2) #dataframe future 1 tháng\n",
    "fu.loc[:,'NAM']=fu['ds'].dt.year\n",
    "fu.loc[:,'THANG']=fu['ds'].dt.month\n",
    "fu.loc[:,'NUM_DAY_OF_MONTH']=fu['ds'].dt.days_in_month\n",
    "df=pd.concat([df,fu])\n",
    "df.set_index('ds', inplace=True)\n",
    "df.drop(columns=['Sum of precip'],inplace=True)\n",
    "df[df['MA_DVIQLY']=='PC10AA']"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "           MA_DVIQLY   NAM  THANG  NUM_DAY_OF_MONTH SO_LUONG_KH  \\\n",
       "ds                                                                \n",
       "2018-01-01    PC10AA  2018      1                31       75436   \n",
       "2018-02-01    PC10AA  2018      2                28       75778   \n",
       "2018-03-01    PC10AA  2018      3                31       76129   \n",
       "2018-04-01    PC10AA  2018      4                30       76343   \n",
       "2018-05-01    PC10AA  2018      5                31       76290   \n",
       "...              ...   ...    ...               ...         ...   \n",
       "2024-02-01    PC10AA  2024      2                29       86897   \n",
       "2024-03-01    PC10AA  2024      3                31       86891   \n",
       "2024-04-01    PC10AA  2024      4                30       87073   \n",
       "2024-05-01    PC10AA  2024      5                31        None   \n",
       "2024-06-01    PC10AA  2024      6                30        None   \n",
       "\n",
       "           THUONG_PHAM_D1M SO_LUONG_KH_DMTMN SAN_LUONG_DMTMN CONG_SUAT_DMTMN  \\\n",
       "ds                                                                             \n",
       "2018-01-01        22780144                 1             175              25   \n",
       "2018-02-01        20493846                 0               0               0   \n",
       "2018-03-01        22984151                 0               0               0   \n",
       "2018-04-01        22867098                 0               0               0   \n",
       "2018-05-01        23109768                 0               0               0   \n",
       "...                    ...               ...             ...             ...   \n",
       "2024-02-01        26789128               888         7164693           64707   \n",
       "2024-03-01        31633176               888         7884863           64707   \n",
       "2024-04-01        34563110               888         7836382           64707   \n",
       "2024-05-01            None              None            None            None   \n",
       "2024-06-01            None              None            None            None   \n",
       "\n",
       "            Average of temp  ...  NN_5104  NN_5200  NN_5301  NN_5302  NN_5400  \\\n",
       "ds                           ...                                                \n",
       "2018-01-01            22.13  ...   135418   530046    11224      147        0   \n",
       "2018-02-01            21.86  ...   123479   496514    10527      100        0   \n",
       "2018-03-01            23.83  ...   145696   526196    11401       73        0   \n",
       "2018-04-01            25.62  ...   155657   480226    11058      347        0   \n",
       "2018-05-01            25.30  ...   172475   475260    11492      410        0   \n",
       "...                     ...  ...      ...      ...      ...      ...      ...   \n",
       "2024-02-01            23.07  ...   396801   774882        0    97235        0   \n",
       "2024-03-01            24.85  ...   527451   734422        0   134827        0   \n",
       "2024-04-01            27.96  ...   692946   693711        0   125199        0   \n",
       "2024-05-01              NaN  ...     None     None     None     None     None   \n",
       "2024-06-01              NaN  ...     None     None     None     None     None   \n",
       "\n",
       "            NN_5401  NN_5402  NN_5403  NN_5404  NN_5500  \n",
       "ds                                                       \n",
       "2018-01-01   184835        0    89135   756424        0  \n",
       "2018-02-01   167719        0    93051   698024        0  \n",
       "2018-03-01   214709        0    86394   791259        0  \n",
       "2018-04-01   241104        0    71328   786713       16  \n",
       "2018-05-01   267228        0    76623   818733        6  \n",
       "...             ...      ...      ...      ...      ...  \n",
       "2024-02-01   208846        0     8776   725220      670  \n",
       "2024-03-01   281396        0    13195   806856      947  \n",
       "2024-04-01   341160        0    12242   833675      987  \n",
       "2024-05-01     None     None     None     None     None  \n",
       "2024-06-01     None     None     None     None     None  \n",
       "\n",
       "[78 rows x 94 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MA_DVIQLY</th>\n",
       "      <th>NAM</th>\n",
       "      <th>THANG</th>\n",
       "      <th>NUM_DAY_OF_MONTH</th>\n",
       "      <th>SO_LUONG_KH</th>\n",
       "      <th>THUONG_PHAM_D1M</th>\n",
       "      <th>SO_LUONG_KH_DMTMN</th>\n",
       "      <th>SAN_LUONG_DMTMN</th>\n",
       "      <th>CONG_SUAT_DMTMN</th>\n",
       "      <th>Average of temp</th>\n",
       "      <th>...</th>\n",
       "      <th>NN_5104</th>\n",
       "      <th>NN_5200</th>\n",
       "      <th>NN_5301</th>\n",
       "      <th>NN_5302</th>\n",
       "      <th>NN_5400</th>\n",
       "      <th>NN_5401</th>\n",
       "      <th>NN_5402</th>\n",
       "      <th>NN_5403</th>\n",
       "      <th>NN_5404</th>\n",
       "      <th>NN_5500</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ds</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-01</th>\n",
       "      <td>PC10AA</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>75436</td>\n",
       "      <td>22780144</td>\n",
       "      <td>1</td>\n",
       "      <td>175</td>\n",
       "      <td>25</td>\n",
       "      <td>22.13</td>\n",
       "      <td>...</td>\n",
       "      <td>135418</td>\n",
       "      <td>530046</td>\n",
       "      <td>11224</td>\n",
       "      <td>147</td>\n",
       "      <td>0</td>\n",
       "      <td>184835</td>\n",
       "      <td>0</td>\n",
       "      <td>89135</td>\n",
       "      <td>756424</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-01</th>\n",
       "      <td>PC10AA</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>75778</td>\n",
       "      <td>20493846</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21.86</td>\n",
       "      <td>...</td>\n",
       "      <td>123479</td>\n",
       "      <td>496514</td>\n",
       "      <td>10527</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>167719</td>\n",
       "      <td>0</td>\n",
       "      <td>93051</td>\n",
       "      <td>698024</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-01</th>\n",
       "      <td>PC10AA</td>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>76129</td>\n",
       "      <td>22984151</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.83</td>\n",
       "      <td>...</td>\n",
       "      <td>145696</td>\n",
       "      <td>526196</td>\n",
       "      <td>11401</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>214709</td>\n",
       "      <td>0</td>\n",
       "      <td>86394</td>\n",
       "      <td>791259</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-01</th>\n",
       "      <td>PC10AA</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>76343</td>\n",
       "      <td>22867098</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.62</td>\n",
       "      <td>...</td>\n",
       "      <td>155657</td>\n",
       "      <td>480226</td>\n",
       "      <td>11058</td>\n",
       "      <td>347</td>\n",
       "      <td>0</td>\n",
       "      <td>241104</td>\n",
       "      <td>0</td>\n",
       "      <td>71328</td>\n",
       "      <td>786713</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-01</th>\n",
       "      <td>PC10AA</td>\n",
       "      <td>2018</td>\n",
       "      <td>5</td>\n",
       "      <td>31</td>\n",
       "      <td>76290</td>\n",
       "      <td>23109768</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.30</td>\n",
       "      <td>...</td>\n",
       "      <td>172475</td>\n",
       "      <td>475260</td>\n",
       "      <td>11492</td>\n",
       "      <td>410</td>\n",
       "      <td>0</td>\n",
       "      <td>267228</td>\n",
       "      <td>0</td>\n",
       "      <td>76623</td>\n",
       "      <td>818733</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-01</th>\n",
       "      <td>PC10AA</td>\n",
       "      <td>2024</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>86897</td>\n",
       "      <td>26789128</td>\n",
       "      <td>888</td>\n",
       "      <td>7164693</td>\n",
       "      <td>64707</td>\n",
       "      <td>23.07</td>\n",
       "      <td>...</td>\n",
       "      <td>396801</td>\n",
       "      <td>774882</td>\n",
       "      <td>0</td>\n",
       "      <td>97235</td>\n",
       "      <td>0</td>\n",
       "      <td>208846</td>\n",
       "      <td>0</td>\n",
       "      <td>8776</td>\n",
       "      <td>725220</td>\n",
       "      <td>670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-01</th>\n",
       "      <td>PC10AA</td>\n",
       "      <td>2024</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>86891</td>\n",
       "      <td>31633176</td>\n",
       "      <td>888</td>\n",
       "      <td>7884863</td>\n",
       "      <td>64707</td>\n",
       "      <td>24.85</td>\n",
       "      <td>...</td>\n",
       "      <td>527451</td>\n",
       "      <td>734422</td>\n",
       "      <td>0</td>\n",
       "      <td>134827</td>\n",
       "      <td>0</td>\n",
       "      <td>281396</td>\n",
       "      <td>0</td>\n",
       "      <td>13195</td>\n",
       "      <td>806856</td>\n",
       "      <td>947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-04-01</th>\n",
       "      <td>PC10AA</td>\n",
       "      <td>2024</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>87073</td>\n",
       "      <td>34563110</td>\n",
       "      <td>888</td>\n",
       "      <td>7836382</td>\n",
       "      <td>64707</td>\n",
       "      <td>27.96</td>\n",
       "      <td>...</td>\n",
       "      <td>692946</td>\n",
       "      <td>693711</td>\n",
       "      <td>0</td>\n",
       "      <td>125199</td>\n",
       "      <td>0</td>\n",
       "      <td>341160</td>\n",
       "      <td>0</td>\n",
       "      <td>12242</td>\n",
       "      <td>833675</td>\n",
       "      <td>987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-01</th>\n",
       "      <td>PC10AA</td>\n",
       "      <td>2024</td>\n",
       "      <td>5</td>\n",
       "      <td>31</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-01</th>\n",
       "      <td>PC10AA</td>\n",
       "      <td>2024</td>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>78 rows × 94 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-23T03:42:51.143832Z",
     "iopub.status.busy": "2024-05-23T03:42:51.143551Z",
     "iopub.status.idle": "2024-05-23T03:42:51.176816Z",
     "shell.execute_reply": "2024-05-23T03:42:51.175964Z",
     "shell.execute_reply.started": "2024-05-23T03:42:51.143805Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df[df['MA_DVIQLY']=='PC10AA'][list_fu]"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-23T16:22:14.107538Z",
     "iopub.status.busy": "2024-05-23T16:22:14.107246Z",
     "iopub.status.idle": "2024-05-23T16:22:14.770233Z",
     "shell.execute_reply": "2024-05-23T16:22:14.769477Z",
     "shell.execute_reply.started": "2024-05-23T16:22:14.107507Z"
    },
    "metadata": {},
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-29T08:16:30.951316Z",
     "start_time": "2024-05-29T08:16:30.585021Z"
    }
   },
   "source": [
    "y=  TimeSeries.from_group_dataframe(df=df,group_cols='MA_DVIQLY',value_cols=list_y,static_cols=list_static)\n",
    "lag=TimeSeries.from_group_dataframe(df=df,group_cols='MA_DVIQLY',value_cols=list_lag,static_cols=list_static)\n",
    "fu=TimeSeries.from_group_dataframe(df=df,group_cols='MA_DVIQLY',value_cols=list_fu,static_cols=list_static)\n",
    "\n",
    "scaler_y=Scaler()\n",
    "scaler_lag=Scaler()\n",
    "scaler_fu=Scaler()\n",
    "scaler_static_y=StaticCovariatesTransformer()\n",
    "scaler_static_lag=StaticCovariatesTransformer()\n",
    "scaler_static_fu=StaticCovariatesTransformer()\n",
    "\n",
    "y=  scaler_static_y.fit_transform(y)\n",
    "lag=scaler_static_lag.fit_transform(lag)\n",
    "fu= scaler_static_fu.fit_transform(fu)\n",
    "\n",
    "nom_y=  scaler_y.fit_transform(y)\n",
    "nom_lag=scaler_lag.fit_transform(lag)\n",
    "nom_fu= scaler_fu.fit_transform(fu)\n"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# test=[8,7,6,5,4,3,2,1]\n",
    "# test[-6:],test[:-1],test[-6:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# back_step=1\n",
    "# n_step=2\n",
    "# len_val=35\n",
    "\n",
    "# train_y  =[i[:-n_step-back_step] for i in nom_y]\n",
    "# train_lag=[i[:-n_step-back_step] for i in nom_lag]\n",
    "# train_fu =[i[:-back_step] for i in nom_fu] if back_step>0 else [i for i in nom_fu]\n",
    "\n",
    "# val_y    =[i[-len_val-back_step:-n_step-back_step] for i in nom_y]\n",
    "# val_lag  =[i[-len_val-back_step:-n_step-back_step] for i in nom_lag]\n",
    "# val_fu   =[i[-len_val-back_step:-back_step] for i in nom_fu] if back_step>0 else [i[-len_val:] for i in nom_fu]\n",
    "\n",
    "# val_metric=[i[-n_step-back_step:-back_step] for i in nom_y] if back_step>0 else [i[-n_step:] for i in nom_y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T04:05:53.664673Z",
     "iopub.status.busy": "2024-05-13T04:05:53.663667Z",
     "iopub.status.idle": "2024-05-13T04:05:53.697314Z",
     "shell.execute_reply": "2024-05-13T04:05:53.696027Z",
     "shell.execute_reply.started": "2024-05-13T04:05:53.664634Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "nom_fu[0].pd_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "nom_lag[1].static_covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "lag[4].static_covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# model = TiDEModel(\n",
    "#     input_chunk_length=25,\n",
    "#     output_chunk_length=2,\n",
    "#     n_epochs=50,\n",
    "#     random_state=0,\n",
    "#     batch_size=64,\n",
    "#     model_name='my_model', save_checkpoints=True,\n",
    "#     force_reset=True,\n",
    "#     use_reversible_instance_norm=True,\n",
    "#     **generate_torch_kwargs()\n",
    "# )\n",
    "\n",
    "# # model.trainer_params[\"enable_progress_bar\"] = False\n",
    "# model.fit(train_y,train_lag,train_fu,val_y,val_lag,val_fu)\n",
    "# print(glob.glob('/kaggle/working/*/*/*/*'))\n",
    "# # model.fit(nom_y,past_covariates=nom_lag,future_covariates=nom_fu)\n",
    "# best_model = model.load_from_checkpoint(model_name='my_model', best=True)\n",
    "# pred_list = scaler_y.inverse_transform(best_model.predict(n=2, series=train_y, past_covariates=train_lag, future_covariates=train_fu))\n",
    "# total=concatenate(pred_list,axis=1).pd_dataframe()\n",
    "# total['PC10']=total.sum(axis=1)\n",
    "# total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# dfp.tail(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-22T06:01:04.974314Z",
     "iopub.status.busy": "2024-05-22T06:01:04.973994Z",
     "iopub.status.idle": "2024-05-22T06:01:04.980929Z",
     "shell.execute_reply": "2024-05-22T06:01:04.979852Z",
     "shell.execute_reply.started": "2024-05-22T06:01:04.974280Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%pdb on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# print(glob.glob('/kaggle/working/*/*/*/*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# results=None\n",
    "\n",
    "# for i in range(0,12):\n",
    "#     back_step=i\n",
    "#     n_step=2\n",
    "#     len_val=35\n",
    "\n",
    "#     train_y  =[i[:-n_step-back_step] for i in nom_y]\n",
    "#     train_lag=[i[:-n_step-back_step] for i in nom_lag]\n",
    "#     train_fu =[i[:-back_step] for i in nom_fu] if back_step>0 else [i for i in nom_fu]\n",
    "\n",
    "#     val_y    =[i[-len_val-back_step:-n_step-back_step] for i in nom_y]\n",
    "#     val_lag  =[i[-len_val-back_step:-n_step-back_step] for i in nom_lag]\n",
    "#     val_fu   =[i[-len_val-back_step:-back_step] for i in nom_fu] if back_step>0 else [i[-len_val:] for i in nom_fu]\n",
    "\n",
    "#     val_metric=[i[-n_step-back_step:-back_step] for i in nom_y] if back_step>0 else [i[-n_step:] for i in nom_y]\n",
    "\n",
    "#     model = TiDEModel(\n",
    "#         input_chunk_length=25,\n",
    "#         output_chunk_length=2,\n",
    "#         n_epochs=20,\n",
    "#         num_encoder_layers=3,\n",
    "#         num_decoder_layers=3,\n",
    "#         decoder_output_dim=32,\n",
    "#         random_state=10,\n",
    "#         batch_size=4,\n",
    "#         dropout=0.2,\n",
    "#         optimizer_kwargs={\"lr\": 5e-5},\n",
    "#         model_name='my_model', save_checkpoints=True,\n",
    "#         force_reset=True,\n",
    "#         use_reversible_instance_norm=True,\n",
    "#         **generate_torch_kwargs()\n",
    "#     )\n",
    "\n",
    "#     # model.trainer_params[\"enable_progress_bar\"] = False\n",
    "#     model.fit(train_y,train_lag,train_fu,val_y,val_lag,val_fu)\n",
    "#     print(glob.glob('/kaggle/working/*/*/*/*'))\n",
    "# #     model.fit(nom_y,past_covariates=nom_lag,future_covariates=nom_fu)\n",
    "#     best_model = model.load_from_checkpoint(model_name='my_model', best=True)\n",
    "#     pred_list = scaler_y.inverse_transform(best_model.predict(n=2, series=train_y, past_covariates=train_lag, future_covariates=train_fu))\n",
    "#     total=concatenate(pred_list,axis=1).pd_dataframe()\n",
    "#     total['PC10']=total.sum(axis=1)\n",
    "#     total=total.tail(1)\n",
    "    \n",
    "#     results = total if results is None else pd.concat([total,results])\n",
    "#     print(total['PC10'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# from lightning.pytorch.callbacks import Callback\n",
    "\n",
    "# class MyCallback(Callback):\n",
    "#     def on_validation_end(self, trainer, pl_module):\n",
    "#         print('Validation epoch {} ended'.format(trainer.current_epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-12T13:19:00.896109Z",
     "iopub.status.busy": "2024-05-12T13:19:00.895763Z",
     "iopub.status.idle": "2024-05-12T13:19:01.052960Z",
     "shell.execute_reply": "2024-05-12T13:19:01.051686Z",
     "shell.execute_reply.started": "2024-05-12T13:19:00.896078Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from lightning.pytorch import Trainer\n",
    "from lightning.pytorch.callbacks import Callback\n",
    "from lightning.pytorch.demos.boring_classes import BoringDataModule, BoringModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-12T13:23:59.300239Z",
     "iopub.status.busy": "2024-05-12T13:23:59.299944Z",
     "iopub.status.idle": "2024-05-12T13:23:59.308648Z",
     "shell.execute_reply": "2024-05-12T13:23:59.307210Z",
     "shell.execute_reply.started": "2024-05-12T13:23:59.300210Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# class PredictAfterValidationCallback(Callback):\n",
    "#     def setup(self, trainer, pl_module, stage):\n",
    "#         if stage in (\"fit\", \"validate\"):\n",
    "#             # setup the predict data even for fit/validate, as we will call it during `on_validation_epoch_end`\n",
    "#             trainer.datamodule.setup(\"validate\")\n",
    "\n",
    "#     def on_validation_epoch_end(self, trainer, pl_module):\n",
    "#         if trainer.sanity_checking:  # optional skip\n",
    "#             return\n",
    "#         print(\"Start predicting!\")\n",
    "#         # this will fetch the dataloader from the LM or LDM\n",
    "#         predict_dataloader = trainer._data_connector._predict_dataloader_source.dataloader()\n",
    "#         for i, batch in enumerate(predict_dataloader):\n",
    "#             # this will move the batch to device using the LM or LDM\n",
    "#             batch = pl_module._apply_batch_transfer_handler(batch)\n",
    "#             # manually run the predict step\n",
    "#             out = pl_module.predict_step(batch, i)\n",
    "#             print(i, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T06:19:17.823099Z",
     "iopub.status.busy": "2024-05-13T06:19:17.822702Z",
     "iopub.status.idle": "2024-05-13T06:19:17.829840Z",
     "shell.execute_reply": "2024-05-13T06:19:17.828395Z",
     "shell.execute_reply.started": "2024-05-13T06:19:17.823060Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from darts.utils.losses import MapeLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-23T05:34:46.391396Z",
     "iopub.status.busy": "2024-05-23T05:34:46.391100Z",
     "iopub.status.idle": "2024-05-23T05:34:46.397517Z",
     "shell.execute_reply": "2024-05-23T05:34:46.395663Z",
     "shell.execute_reply.started": "2024-05-23T05:34:46.391364Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from darts.metrics.metrics import rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T14:01:05.595183Z",
     "start_time": "2024-05-26T13:59:29.531618Z"
    },
    "execution": {
     "iopub.execute_input": "2024-05-23T17:42:33.050012Z",
     "iopub.status.busy": "2024-05-23T17:42:33.049600Z"
    },
    "metadata": {},
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 13/13 [00:01<00:00,  9.27it/s, train_loss=0.0102, val_loss=0.0401, val_MeanAbsoluteError=0.163, train_MeanAbsoluteError=0.096]\n",
      "[]\n",
      "ds\n",
      "2024-05-01    1.445579e+08\n",
      "2024-06-01    1.413813e+08\n",
      "Freq: MS, Name: PC10, dtype: float64\n",
      "Epoch 14: 100%|██████████| 12/12 [00:01<00:00,  9.37it/s, train_loss=0.00818, val_loss=0.0192, val_MeanAbsoluteError=0.113, train_MeanAbsoluteError=0.105]\n",
      "[]\n",
      "ds\n",
      "2024-04-01    1.473120e+08\n",
      "2024-05-01    1.470121e+08\n",
      "Freq: MS, Name: PC10, dtype: float64\n",
      "Epoch 6:   0%|          | 0/12 [00:00<?, ?it/s, train_loss=0.0316, val_loss=0.0447, val_MeanAbsoluteError=0.139, train_MeanAbsoluteError=0.104]         []\n",
      "ds\n",
      "2024-03-01    1.373352e+08\n",
      "2024-04-01    1.378257e+08\n",
      "Freq: MS, Name: PC10, dtype: float64\n",
      "Epoch 7:   0%|          | 0/12 [00:00<?, ?it/s, train_loss=0.0104, val_loss=0.113, val_MeanAbsoluteError=0.210, train_MeanAbsoluteError=0.121]         "
     ]
    }
   ],
   "source": [
    "results1=None\n",
    "results2=None\n",
    "# metric=torchmetrics.MeanAbsoluteError()\n",
    "metric=torchmetrics.MeanAbsoluteError()\n",
    "for i in range(0,8):\n",
    "    back_step=i\n",
    "    n_step=2\n",
    "    len_val=4\n",
    "    input_chunk_length=6\n",
    "\n",
    "    train_y  =[i[:-n_step-back_step-len_val+len_val] for i in nom_y]\n",
    "    train_lag=[i[:-n_step-back_step-len_val+len_val] for i in nom_lag]\n",
    "    train_fu =[i[:-back_step-len_val+len_val] for i in nom_fu] if back_step>0 else [i for i in nom_fu]\n",
    "\n",
    "    val_y    =[i[-len_val-input_chunk_length-back_step:-n_step-back_step] for i in nom_y]\n",
    "    val_lag  =[i[-len_val-input_chunk_length-back_step:-n_step-back_step] for i in nom_lag]\n",
    "    val_fu   =[i[-len_val-input_chunk_length-back_step:-back_step] for i in nom_fu] \\\n",
    "                if back_step>0 else [i[-len_val-input_chunk_length:] for i in nom_fu]\n",
    "\n",
    "    test_y  =[i[:-n_step-back_step] for i in nom_y]\n",
    "    test_lag=[i[:-n_step-back_step] for i in nom_lag]\n",
    "    test_fu =[i[:-back_step] for i in nom_fu] if back_step>0 else [i for i in nom_fu]\n",
    "\n",
    "    val_metric=[i[-n_step-back_step:-back_step] for i in nom_y] if back_step>0 else [i[-n_step:] for i in nom_y]\n",
    " \n",
    "    model = iTransformerModel(\n",
    "        input_chunk_length=input_chunk_length,\n",
    "        output_chunk_length=n_step,\n",
    "        n_epochs=15,\n",
    "        num_encoder_layers=3,\n",
    "        num_decoder_layers=3,\n",
    "        d_model=64,\n",
    "        # decoder_output_dim=32,\n",
    "        torch_metrics=metric,\n",
    "        # hidden_size=128,\n",
    "#         use_layer_norm=True,\n",
    "        loss_fn=CustomLoss(),\n",
    "        random_state=100,\n",
    "        batch_size=16,\n",
    "        dropout=0.2,\n",
    "        activation='SwiGLU',\n",
    "        monitor_checkpoint=\"val_MeanAbsoluteError\",\n",
    "#         use_layer_norm=True,\n",
    "        optimizer_cls=torch.optim.AdamW,\n",
    "        optimizer_kwargs={\"lr\": 1e-3,\n",
    "                          \"amsgrad\":True,\n",
    "                          \"eps\":1e-12},\n",
    "        model_name='my_model', save_checkpoints=True,\n",
    "        force_reset=True,\n",
    "        use_reversible_instance_norm=True,\n",
    "        pl_trainer_kwargs= {\n",
    "            \"accelerator\": \"cpu\",\n",
    "            \"callbacks\": [TFMProgressBar(enable_train_bar_only=True,refresh_rate=50,)],\n",
    "            \"limit_train_batches\":0.2,\n",
    "        },\n",
    "    )\n",
    "\n",
    "    # model.trainer_params[\"enable_progress_bar\"] = False\n",
    " \n",
    "    model.fit(train_y,train_lag,None,val_y,val_lag,None)\n",
    "    print(sorted(glob.glob('/kaggle/working/*/*/*/*')))\n",
    "    best_model = model.load_from_checkpoint(model_name='my_model', best=True)\n",
    "    pred_list = scaler_static_y.inverse_transform(scaler_y.inverse_transform(best_model.predict(n=n_step, series=test_y, past_covariates=test_lag, future_covariates=None)))\n",
    "#     total=concatenate(pred_list,axis=0).pd_dataframe()\n",
    "    total=pd.concat([pred_list[i]['THUONG_PHAM_D1M'].pd_dataframe() for i in range(len(pred_list))],axis=1,)\n",
    "    total.columns=[pred_list[i].static_covariates['MA_DVIQLY']['THUONG_PHAM_D1M'] for i in range(len(pred_list))]\n",
    "    total['PC10']=total.sum(axis=1)\n",
    "    total=total.tail(2)\n",
    "    \n",
    "    results1 = total.head(1) if results1 is None else pd.concat([total.head(1),results1])\n",
    "    results2 = total.tail(1) if results2 is None else pd.concat([total.tail(1),results2])\n",
    "    print(total['PC10'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glob.glob(\"./darts_logs/my_model/checkpoints/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# results1=None\n",
    "# results2=None\n",
    "\n",
    "# for i in range(0,18):\n",
    "#     back_step=i\n",
    "#     n_step=2\n",
    "#     len_val=4\n",
    "#     input_chunk_length=25\n",
    "\n",
    "#     train_y  =[i[:-n_step-back_step-len_val+len_val] for i in nom_y]\n",
    "#     train_lag=[i[:-n_step-back_step-len_val+len_val] for i in nom_lag]\n",
    "#     train_fu =[i[:-back_step-len_val+len_val] for i in nom_fu] if back_step>0 else [i for i in nom_fu]\n",
    "\n",
    "#     val_y    =[i[-len_val-input_chunk_length-back_step:-n_step-back_step] for i in nom_y]\n",
    "#     val_lag  =[i[-len_val-input_chunk_length-back_step:-n_step-back_step] for i in nom_lag]\n",
    "#     val_fu   =[i[-len_val-input_chunk_length-back_step:-back_step] for i in nom_fu] \\\n",
    "#                 if back_step>0 else [i[-len_val-input_chunk_length:] for i in nom_fu]\n",
    "#     test_y  =[i[:-n_step-back_step] for i in nom_y]\n",
    "#     test_lag=[i[:-n_step-back_step] for i in nom_lag]\n",
    "#     test_fu =[i[:-back_step] for i in nom_fu] if back_step>0 else [i for i in nom_fu]\n",
    "\n",
    "#     val_metric=[i[-n_step-back_step:-back_step] for i in nom_y] if back_step>0 else [i[-n_step:] for i in nom_y]\n",
    "# #     ipdb.set_trace()\n",
    "#     model = TFTModel(\n",
    "#         input_chunk_length=input_chunk_length,\n",
    "#         output_chunk_length=n_step,\n",
    "#         n_epochs=200,\n",
    "# #         num_encoder_layers=5,\n",
    "# #         num_decoder_layers=5,\n",
    "# #         decoder_output_dim=32,\n",
    "#         torch_metrics=torchmetrics.MeanAbsolutePercentageError(),\n",
    "# #         hidden_size=32,\n",
    "# #         use_layer_norm=True,\n",
    "# #         loss_fn=LogCoshLoss(),\n",
    "#         random_state=50,\n",
    "#         batch_size=32,\n",
    "#         dropout=0.2,\n",
    "# #         activation=\"SwiGLU\",\n",
    "# #         use_layer_norm=True,\n",
    "#         optimizer_cls=torch.optim.AdamW,\n",
    "#         optimizer_kwargs={\"lr\": 5e-5,\n",
    "#                           \"amsgrad\":True,\n",
    "#                           \"eps\":1e-10},\n",
    "#         model_name='my_model', save_checkpoints=True,\n",
    "#         force_reset=True,\n",
    "#         use_reversible_instance_norm=True,\n",
    "#         pl_trainer_kwargs= {\n",
    "#             \"accelerator\": \"cpu\",\n",
    "#             \"callbacks\": [TFMProgressBar(enable_train_bar_only=True,refresh_rate=50,)],\n",
    "# #             \"limit_train_batches\":0.2,\n",
    "#         },\n",
    "#     )\n",
    "\n",
    "#     # model.trainer_params[\"enable_progress_bar\"] = False\n",
    "#     model.fit(train_y,past_covariates=train_lag,future_covariates=train_fu,val_series=val_y,val_past_covariates=val_lag,val_future_covariates=val_fu,)\n",
    "#     print(sorted(glob.glob('/kaggle/working/*/*/*/*')))\n",
    "#     best_model = model.load_from_checkpoint(model_name='my_model', best=True)\n",
    "#     pred_list = scaler_static_y.inverse_transform(scaler_y.inverse_transform(model.predict(n=n_step, series=test_y, past_covariates=test_lag)))\n",
    "# #     total=concatenate(pred_list,axis=0).pd_dataframe()\n",
    "#     total=pd.concat([pred_list[i]['THUONG_PHAM_D1M'].pd_dataframe() for i in range(len(pred_list))],axis=1,)\n",
    "#     total.columns=[pred_list[i].static_covariates['MA_DVIQLY']['THUONG_PHAM_D1M'] for i in range(len(pred_list))]\n",
    "#     total['PC10']=total.sum(axis=1)\n",
    "#     total=total.tail(2)\n",
    "    \n",
    "#     results1 = total.head(1) if results1 is None else pd.concat([total.head(1),results1])\n",
    "#     results2 = total.tail(1) if results2 is None else pd.concat([total.tail(1),results2])\n",
    "#     print(total['PC10'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T06:08:41.555610Z",
     "iopub.status.busy": "2024-05-21T06:08:41.555272Z",
     "iopub.status.idle": "2024-05-21T06:08:41.830444Z",
     "shell.execute_reply": "2024-05-21T06:08:41.829553Z",
     "shell.execute_reply.started": "2024-05-21T06:08:41.555579Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "pred_list = scaler_static_y.inverse_transform(scaler_y.inverse_transform(model.predict(n=n_step, series=test_y, past_covariates=test_lag, future_covariates=test_fu)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "total=pd.concat([pred_list[i]['THUONG_PHAM_D1M'].pd_dataframe() for i in range(len(pred_list))],axis=1,)\n",
    "total.columns=[pred_list[i].static_covariates['MA_DVIQLY']['THUONG_PHAM_D1M'] for i in range(len(pred_list))]\n",
    "total['PC10']=total.sum(axis=1)\n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "pred_list = scaler_y.inverse_transform(model.predict(n=n_step, series=test_y, past_covariates=test_lag, future_covariates=test_fu))\n",
    "total=concatenate(pred_list,axis=1).pd_dataframe()\n",
    "total['PC10']=total.sum(axis=1)\n",
    "total=total.tail(2)\n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-23T17:23:33.848042Z",
     "iopub.status.busy": "2024-05-23T17:23:33.847726Z",
     "iopub.status.idle": "2024-05-23T17:23:33.883867Z",
     "shell.execute_reply": "2024-05-23T17:23:33.882661Z",
     "shell.execute_reply.started": "2024-05-23T17:23:33.848010Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "A=pd.concat([dfp.tail(19)['total'],results1['PC10']],axis=1)\n",
    "A['sai_so_1T_%']=(A['PC10']-A['total'])/A['PC10']*100\n",
    "A=A.rename(columns={'total':'thuc_te','PC10':'du_bao_truoc_1T'})\n",
    "A=pd.concat([A,results2['PC10']],axis=1)\n",
    "A['sai_so_2T_%']=(A['PC10']-A['thuc_te'])/A['PC10']*100\n",
    "A=A.rename(columns={'PC10':'du_bao_truoc_2T'})\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# model = TiDEModel(\n",
    "#     input_chunk_length=15,\n",
    "#     output_chunk_length=2,\n",
    "#     n_epochs=6,\n",
    "# #     random_state=20,\n",
    "#     batch_size=1,\n",
    "#     dropout=0.1,\n",
    "#     optimizer_kwargs={\"lr\": 1e-4},\n",
    "#     model_name='my_model', save_checkpoints=True,\n",
    "#     force_reset=True,\n",
    "#     use_reversible_instance_norm=True,\n",
    "#     **generate_torch_kwargs()\n",
    "# )\n",
    "\n",
    "# # model.trainer_params[\"enable_progress_bar\"] = False\n",
    "# model.fit(train_y,train_lag,train_fu,val_y,val_lag,val_fu)\n",
    "# print(glob.glob('/kaggle/working/*/*/*/*'))\n",
    "# # model.fit(nom_y,past_covariates=nom_lag,future_covariates=nom_fu)\n",
    "# best_model = model.load_from_checkpoint(model_name='my_model', best=True)\n",
    "# pred_list = scaler_y.inverse_transform(best_model.predict(n=2, series=train_y, past_covariates=train_lag, future_covariates=train_fu))\n",
    "# total=concatenate(pred_list,axis=1).pd_dataframe()\n",
    "# total['PC10']=total.sum(axis=1)\n",
    "# total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# best_model = model.load_from_checkpoint(model_name='my_model', best=False)\n",
    "# pred_list = scaler_y.inverse_transform(best_model.predict(n=2, series=train_y, past_covariates=train_lag, future_covariates=train_fu))\n",
    "# total=concatenate(pred_list,axis=1).pd_dataframe()\n",
    "# total['PC10']=total.sum(axis=1)\n",
    "# total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from lightning.pytorch import LightningModule\n",
    "from lightning.pytorch import Trainer\n",
    "from lightning.pytorch import Callback\n",
    "import optuna\n",
    "\n",
    "class PyTorchLightningPruningCallback(Callback):\n",
    "    \"\"\"PyTorch Lightning callback to prune unpromising trials.\n",
    "    See `the example <https://github.com/optuna/optuna-examples/blob/\n",
    "    main/pytorch/pytorch_lightning_simple.py>`__\n",
    "    if you want to add a pruning callback which observes accuracy.\n",
    "    Args:\n",
    "        trial:\n",
    "            A :class:`~optuna.trial.Trial` corresponding to the current evaluation of the\n",
    "            objective function.\n",
    "        monitor:\n",
    "            An evaluation metric for pruning, e.g., ``val_loss`` or\n",
    "            ``val_acc``. The metrics are obtained from the returned dictionaries from e.g.\n",
    "            ``pytorch_lightning.LightningModule.training_step`` or\n",
    "            ``pytorch_lightning.LightningModule.validation_epoch_end`` and the names thus depend on\n",
    "            how this dictionary is formatted.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, trial: optuna.trial.Trial, monitor: str) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self._trial = trial\n",
    "        self.monitor = monitor\n",
    "        self._best_score = None\n",
    "\n",
    "    def on_validation_end(self, trainer: Trainer, pl_module: LightningModule) -> None:\n",
    "        # When the trainer calls `on_validation_end` for sanity check,\n",
    "        # do not call `trial.report` to avoid calling `trial.report` multiple times\n",
    "        # at epoch 0. The related page is\n",
    "        # https://github.com/PyTorchLightning/pytorch-lightning/issues/1391.\n",
    "        if trainer.sanity_checking:\n",
    "            return\n",
    "\n",
    "        epoch = pl_module.current_epoch\n",
    "\n",
    "        current_score = trainer.callback_metrics.get(self.monitor)\n",
    "        if current_score is None:\n",
    "            message = (\n",
    "                \"The metric '{}' is not in the evaluation logs for pruning. \"\n",
    "                \"Please make sure you set the correct metric name.\".format(self.monitor)\n",
    "            )\n",
    "            warnings.warn(message)\n",
    "            return\n",
    "        if self._best_score is None or current_score < self._best_score:\n",
    "            self._best_score = current_score\n",
    "            trainer.save_checkpoint(\"best_checkpoint.ckpt\")\n",
    "            \n",
    "        self._trial.report(current_score, step=epoch)\n",
    "        if self._trial.should_prune() and epoch>0:\n",
    "            message = \"Trial was pruned at epoch {}.\".format(epoch)\n",
    "            raise optuna.TrialPruned(message)\n",
    "    def on_train_end(self, trainer, pl_module):\n",
    "        print(f\"epoch {pl_module.current_epoch}\",end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from lightning.pytorch.callbacks import EarlyStopping\n",
    "import optuna\n",
    "# from optuna.integration import PyTorchLightningPruningCallback\n",
    "from darts.metrics import smape\n",
    "\n",
    "back_step=2\n",
    "n_step=2\n",
    "len_val=4\n",
    "input_chunk_length=25\n",
    "\n",
    "train_y  =[i[:-n_step-back_step-len_val+len_val] for i in nom_y]\n",
    "train_lag=[i[:-n_step-back_step-len_val+len_val] for i in nom_lag]\n",
    "train_fu =[i[:-back_step-len_val+len_val] for i in nom_fu] if back_step>0 else [i for i in nom_fu]\n",
    "\n",
    "val_y    =[i[-len_val-input_chunk_length-back_step:-n_step-back_step] for i in nom_y]\n",
    "val_lag  =[i[-len_val-input_chunk_length-back_step:-n_step-back_step] for i in nom_lag]\n",
    "val_fu   =[i[-len_val-input_chunk_length-back_step:-back_step] for i in nom_fu] \\\n",
    "            if back_step>0 else [i[-len_val-input_chunk_length:] for i in nom_fu]\n",
    "\n",
    "test_y  =[i[:-n_step-back_step] for i in nom_y]\n",
    "test_lag=[i[:-n_step-back_step] for i in nom_lag]\n",
    "test_fu =[i[:-back_step] for i in nom_fu] if back_step>0 else [i for i in nom_fu]\n",
    "\n",
    "val_metric=[i[-n_step-back_step:-back_step] for i in nom_y] \\\n",
    "            if back_step>0 else [i[-n_step:] for i in nom_y]\n",
    "\n",
    "# define objective function\n",
    "def objective(trial):\n",
    "    # select input and output chunk lengths\n",
    "    n_epochs = trial.suggest_int(\"n_epochs\", 10, 40)\n",
    "\n",
    "    # Other hyperparameters\n",
    "#     dropout = trial.suggest_float(\"dropout\", 0.1, 0.2)\n",
    "    lr = trial.suggest_float(\"lr\", 5e-5, 1e-3, log=True)\n",
    "\n",
    "    # throughout training we'll monitor the validation loss for both pruning and early stopping\n",
    "    pruner = PyTorchLightningPruningCallback(trial, monitor=\"val_loss\")\n",
    "    early_stopper = EarlyStopping(\"val_loss\", min_delta=0.0001, patience=8, verbose=True)\n",
    "\n",
    "    # reproducibility\n",
    "    torch.manual_seed(42)\n",
    "\n",
    "    # build the TCN model\n",
    "    model = TiDEModel(\n",
    "        input_chunk_length=input_chunk_length,\n",
    "        output_chunk_length=n_step,\n",
    "        n_epochs=36,\n",
    "        num_encoder_layers=5,\n",
    "        num_decoder_layers=5,\n",
    "        decoder_output_dim=32,\n",
    "        random_state=20,\n",
    "        batch_size=4,\n",
    "        dropout=0.2,\n",
    "        activation=SwiGLU,\n",
    "        optimizer_kwargs={\"lr\": lr},\n",
    "        model_name='my_model', save_checkpoints=True,\n",
    "        force_reset=True,\n",
    "        use_reversible_instance_norm=True,\n",
    "        pl_trainer_kwargs= {\n",
    "            \"accelerator\": \"cpu\",\n",
    "            \"callbacks\": [TFMProgressBar(enable_train_bar_only=True,refresh_rate=50,)],\n",
    "            \"limit_train_batches\":0.2,\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "    # when validating during training, we can use a slightly longer validation\n",
    "    # set which also contains the first input_chunk_length time steps\n",
    "    # train the model\n",
    "    \n",
    "    model.fit(train_y,train_lag,train_fu,val_y,val_lag,val_fu,verbose=True)\n",
    "\n",
    "    # reload best model over course of training\n",
    "#     model = TiDEModel.load_from_checkpoint(model_name='my_model')\n",
    "\n",
    "    # Evaluate how good it is on the validation set, using sMAPE\n",
    "    preds = model.predict(n=2, series=train_y, past_covariates=train_lag, future_covariates=train_fu)\n",
    "    smapes = smape(val_metric, preds, n_jobs=-1)\n",
    "    smape_val = np.mean(smapes)\n",
    "    \n",
    "#     ipdb.set_trace()\n",
    "    \n",
    "    return smape_val if smape_val != np.nan else float(\"inf\")\n",
    "\n",
    "# for convenience, print some optimization trials information\n",
    "def print_callback(study, trial):\n",
    "    trial_params = {k: format(v, '.4e') for k, v in trial.params.items()}\n",
    "    study_best_trial_params={k: format(v, '.4e') for k, v in study.best_trial.params.items()}\n",
    "    print(f\"Current value: {trial.value:.5e},params: {trial_params}\")\n",
    "    print(f\"Best value: {study.best_value:.5e},params: {study_best_trial_params}\")\n",
    "\n",
    "# optimize hyperparameters by minimizing the sMAPE on the validation set\n",
    "if __name__ == \"__main__\":\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    study.optimize(objective, n_trials=15, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import torch\n",
    "# from pytorch_lightning.callbacks import EarlyStopping\n",
    "# from sklearn.preprocessing import MaxAbsScaler\n",
    "\n",
    "# from darts.dataprocessing.transformers import Scaler\n",
    "# from darts.datasets import AirPassengersDataset\n",
    "# from darts.metrics import smape\n",
    "# from darts.models import TCNModel\n",
    "# from darts.utils.likelihood_models import GaussianLikelihood\n",
    "\n",
    "# # load data\n",
    "# series = AirPassengersDataset().load().astype(np.float32)\n",
    "\n",
    "# # split in train / validation (note: in practice we would also need a test set)\n",
    "# VAL_LEN = 36\n",
    "# train, val = series[:-VAL_LEN], series[-VAL_LEN:]\n",
    "\n",
    "# # scale\n",
    "# scaler = Scaler(MaxAbsScaler())\n",
    "# train = scaler.fit_transform(train)\n",
    "# val = scaler.transform(val)\n",
    "\n",
    "# # define objective function\n",
    "# def objective(trial):\n",
    "#     # select input and output chunk lengths\n",
    "#     in_len = trial.suggest_int(\"in_len\", 12, 36)\n",
    "#     out_len = trial.suggest_int(\"out_len\", 1, in_len-1)\n",
    "\n",
    "#     # Other hyperparameters\n",
    "#     kernel_size = trial.suggest_int(\"kernel_size\", 2, 5)\n",
    "#     num_filters = trial.suggest_int(\"num_filters\", 1, 5)\n",
    "#     weight_norm = trial.suggest_categorical(\"weight_norm\", [False, True])\n",
    "#     dilation_base = trial.suggest_int(\"dilation_base\", 2, 4)\n",
    "#     dropout = trial.suggest_float(\"dropout\", 0.0, 0.4)\n",
    "#     lr = trial.suggest_float(\"lr\", 5e-5, 1e-3, log=True)\n",
    "#     include_year = trial.suggest_categorical(\"year\", [False, True])\n",
    "\n",
    "#     # throughout training we'll monitor the validation loss for both pruning and early stopping\n",
    "#     pruner = PyTorchLightningPruningCallback(trial, monitor=\"val_loss\")\n",
    "#     early_stopper = EarlyStopping(\"val_loss\", min_delta=0.001, patience=3, verbose=True)\n",
    "#     callbacks = [pruner, early_stopper]\n",
    "\n",
    "#     # detect if a GPU is available\n",
    "#     if torch.cuda.is_available():\n",
    "#         num_workers = 4\n",
    "#     else:\n",
    "#         num_workers = 0\n",
    "\n",
    "#     pl_trainer_kwargs = {\n",
    "#         \"accelerator\": \"auto\",\n",
    "#         \"callbacks\": callbacks,\n",
    "#     }\n",
    "\n",
    "#     # optionally also add the (scaled) year value as a past covariate\n",
    "#     if include_year:\n",
    "#         encoders = {\"datetime_attribute\": {\"past\": [\"year\"]},\n",
    "#                     \"transformer\": Scaler()}\n",
    "#     else:\n",
    "#         encoders = None\n",
    "\n",
    "#     # reproducibility\n",
    "#     torch.manual_seed(42)\n",
    "\n",
    "#     # build the TCN model\n",
    "#     model = TCNModel(\n",
    "#         input_chunk_length=in_len,\n",
    "#         output_chunk_length=out_len,\n",
    "#         batch_size=32,\n",
    "#         n_epochs=100,\n",
    "#         nr_epochs_val_period=1,\n",
    "#         kernel_size=kernel_size,\n",
    "#         num_filters=num_filters,\n",
    "#         weight_norm=weight_norm,\n",
    "#         dilation_base=dilation_base,\n",
    "#         dropout=dropout,\n",
    "#         optimizer_kwargs={\"lr\": lr},\n",
    "#         add_encoders=encoders,\n",
    "#         likelihood=GaussianLikelihood(),\n",
    "#         pl_trainer_kwargs=pl_trainer_kwargs,\n",
    "#         model_name=\"tcn_model\",\n",
    "#         force_reset=True,\n",
    "#         save_checkpoints=True,\n",
    "#     )\n",
    "\n",
    "\n",
    "#     # when validating during training, we can use a slightly longer validation\n",
    "#     # set which also contains the first input_chunk_length time steps\n",
    "#     model_val_set = scaler.transform(series[-(VAL_LEN + in_len) :])\n",
    "\n",
    "#     # train the model\n",
    "#     model.fit(\n",
    "#         series=train,\n",
    "#         val_series=model_val_set,\n",
    "#         num_loader_workers=num_workers,\n",
    "#     )\n",
    "\n",
    "#     # reload best model over course of training\n",
    "#     model = TCNModel.load_from_checkpoint(\"tcn_model\")\n",
    "\n",
    "#     # Evaluate how good it is on the validation set, using sMAPE\n",
    "#     preds = model.predict(series=train, n=VAL_LEN)\n",
    "#     smapes = smape(val, preds, n_jobs=-1, verbose=True)\n",
    "#     smape_val = np.mean(smapes)\n",
    "    \n",
    "#     return smape_val if smape_val != np.nan else float(\"inf\")\n",
    "\n",
    "\n",
    "# # for convenience, print some optimization trials information\n",
    "# def print_callback(study, trial):\n",
    "#     print(f\"Current value: {trial.value}, Current params: {trial.params}\")\n",
    "#     print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")\n",
    "\n",
    "\n",
    "# # optimize hyperparameters by minimizing the sMAPE on the validation set\n",
    "# if __name__ == \"__main__\":\n",
    "#     study = optuna.create_study(direction=\"minimize\")\n",
    "#     study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# pred_list = model_air_milk.predict(n=36, series=[train_air, train_milk])\n",
    "# for series, label in zip(pred_list, [\"air passengers\", \"milk production\"]):\n",
    "#     series.plot(label=f\"forecast {label}\")\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# # generate an DataFrame example\n",
    "# df = pd.DataFrame(\n",
    "#     data={\n",
    "#         \"dates\": [\n",
    "#             \"2020-01-01\",\n",
    "#             \"2020-01-02\",\n",
    "#             \"2020-01-03\",\n",
    "#             \"2020-01-01\",\n",
    "#             \"2020-01-02\",\n",
    "#             \"2020-01-03\",\n",
    "#         ],\n",
    "#         \"comp1\": np.random.random((6,)),\n",
    "#         \"comp2\": np.random.random((6,)),\n",
    "#         \"comp3\": np.random.random((6,)),\n",
    "#         \"ID\": [\"SERIES1\", \"SERIES1\", \"SERIES1\", \"SERIES2\", \"SERIES2\", \"SERIES2\"],\n",
    "#         \"var1\": [0.5, 0.5, 0.5, 0.75, 0.75, 0.75],\n",
    "#     }\n",
    "# )\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# series_multi = TimeSeries.from_group_dataframe(\n",
    "#     df,\n",
    "#     time_col=\"dates\",\n",
    "#     group_cols=\"ID\",  # individual time series are extracted by grouping `df` by `group_cols`\n",
    "#     static_cols=[\n",
    "#         \"var1\"\n",
    "#     ],  # also extract these additional columns as static covariates (without grouping)\n",
    "#     value_cols=[\n",
    "#         \"comp1\",\n",
    "#         \"comp2\",\n",
    "#         \"comp3\",\n",
    "#     ],  # optionally, specify the time varying columns\n",
    "# )\n",
    "\n",
    "# print(f\"\\n{len(series_multi)} series were extracted from the input DataFrame\")\n",
    "# for i, ts in enumerate(series_multi):\n",
    "#     print(f\"Static covariates of series {i}\")\n",
    "#     print(ts.static_covariates)\n",
    "# #     ts[\"comp1\"].plot(label=f\"comp1_series_{i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# from darts.dataprocessing.transformers import StaticCovariatesTransformer\n",
    "\n",
    "# transformer = StaticCovariatesTransformer()\n",
    "# series_transformed = transformer.fit_transform(series_multi)\n",
    "\n",
    "# for i, (ts, ts_scaled) in enumerate(zip(series_multi, series_transformed)):\n",
    "#     print(f\"Original series {i}\")\n",
    "#     print(ts.static_covariates)\n",
    "#     print(f\"Transformed series {i}\")\n",
    "#     print(ts_scaled.static_covariates)\n",
    "#     print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# fu=df[df['ds']>='2024-01-01']\n",
    "# fu.loc[:,'y']=None\n",
    "# fu.loc[:,'DAU_NGUON_NHAN']=None\n",
    "# fu.loc[:,'ds']=fu['ds']+pd.DateOffset(months=+2)\n",
    "# # fu.loc[:,'NAM']=fu['ds'].dt.year\n",
    "# # fu.loc[:,'THANG']=fu['ds'].dt.month\n",
    "# fu.loc[:,'NUM_DAY_OF_MONTH']=fu['ds'].dt.days_in_month\n",
    "# fu\n",
    "# fu=pd.concat([df,fu])\n",
    "# fu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# from datetime import date \n",
    "# import holidays \n",
    "# import pandas as pd\n",
    "\n",
    "# # Select country   \n",
    "# # Print all the holidays in Vietnam in year 2022 \n",
    "# holidays_list = [(date, name) for date, name in holidays.Vietnam(years = [2018,2019,2020,2021,2022,2023,2024]).items()]\n",
    "\n",
    "# # Convert list to DataFrame\n",
    "# df = pd.DataFrame(holidays_list, columns=['Date', 'Holiday'])\n",
    "\n",
    "# # Print DataFrame\n",
    "# df.to_csv('ngay_le.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# Optuna example that optimizes multi-layer perceptrons using PyTorch Lightning.\n",
    "\n",
    "# In this example, we optimize the validation accuracy of fashion product recognition using\n",
    "# PyTorch Lightning, and FashionMNIST. We optimize the neural network architecture. As it is too time\n",
    "# consuming to use the whole FashionMNIST dataset, we here use a small subset of it.\n",
    "\n",
    "# You can run this example as follows, pruning can be turned on and off with the `--pruning`\n",
    "# argument.\n",
    "#     $ python pytorch_lightning_simple.py [--pruning]\n",
    "\n",
    "# \"\"\"\n",
    "\n",
    "# import argparse\n",
    "# import os\n",
    "# from typing import List\n",
    "# from typing import Optional\n",
    "\n",
    "# import lightning.pytorch as pl\n",
    "# import optuna\n",
    "# from optuna.integration import PyTorchLightningPruningCallback\n",
    "# from packaging import version\n",
    "# import torch\n",
    "# from torch import nn\n",
    "# from torch import optim\n",
    "# import torch.nn.functional as F\n",
    "# from torch.utils.data import DataLoader\n",
    "# from torch.utils.data import random_split\n",
    "# from torchvision import datasets\n",
    "# from torchvision import transforms\n",
    "\n",
    "\n",
    "# if version.parse(pl.__version__) < version.parse(\"1.6.0\"):\n",
    "#     raise RuntimeError(\"PyTorch Lightning>=1.6.0 is required for this example.\")\n",
    "\n",
    "# PERCENT_VALID_EXAMPLES = 0.1\n",
    "# BATCHSIZE = 128\n",
    "# CLASSES = 10\n",
    "# EPOCHS = 10\n",
    "# DIR = os.getcwd()\n",
    "\n",
    "\n",
    "# class Net(nn.Module):\n",
    "#     def __init__(self, dropout: float, output_dims: List[int]) -> None:\n",
    "#         super().__init__()\n",
    "#         layers: List[nn.Module] = []\n",
    "\n",
    "#         input_dim: int = 28 * 28\n",
    "#         for output_dim in output_dims:\n",
    "#             layers.append(nn.Linear(input_dim, output_dim))\n",
    "#             layers.append(nn.ReLU())\n",
    "#             layers.append(nn.Dropout(dropout))\n",
    "#             input_dim = output_dim\n",
    "\n",
    "#         layers.append(nn.Linear(input_dim, CLASSES))\n",
    "\n",
    "#         self.layers = nn.Sequential(*layers)\n",
    "\n",
    "#     def forward(self, data: torch.Tensor) -> torch.Tensor:\n",
    "#         logits = self.layers(data)\n",
    "#         return F.log_softmax(logits, dim=1)\n",
    "\n",
    "\n",
    "# class LightningNet(pl.LightningModule):\n",
    "#     def __init__(self, dropout: float, output_dims: List[int]) -> None:\n",
    "#         super().__init__()\n",
    "#         self.model = Net(dropout, output_dims)\n",
    "\n",
    "#     def forward(self, data: torch.Tensor) -> torch.Tensor:\n",
    "#         return self.model(data.view(-1, 28 * 28))\n",
    "\n",
    "#     def training_step(self, batch: List[torch.Tensor], batch_idx: int) -> torch.Tensor:\n",
    "#         data, target = batch\n",
    "#         output = self(data)\n",
    "#         return F.nll_loss(output, target)\n",
    "\n",
    "#     def validation_step(self, batch: List[torch.Tensor], batch_idx: int) -> None:\n",
    "#         data, target = batch\n",
    "#         output = self(data)\n",
    "#         pred = output.argmax(dim=1, keepdim=True)\n",
    "#         accuracy = pred.eq(target.view_as(pred)).float().mean()\n",
    "#         self.log(\"val_acc\", accuracy)\n",
    "#         self.log(\"hp_metric\", accuracy, on_step=False, on_epoch=True)\n",
    "\n",
    "#     def configure_optimizers(self) -> optim.Optimizer:\n",
    "#         return optim.Adam(self.model.parameters())\n",
    "\n",
    "\n",
    "# class FashionMNISTDataModule(pl.LightningDataModule):\n",
    "#     def __init__(self, data_dir: str, batch_size: int):\n",
    "#         super().__init__()\n",
    "#         self.data_dir = data_dir\n",
    "#         self.batch_size = batch_size\n",
    "\n",
    "#     def setup(self, stage: Optional[str] = None) -> None:\n",
    "#         self.mnist_test = datasets.FashionMNIST(\n",
    "#             self.data_dir, train=False, download=True, transform=transforms.ToTensor()\n",
    "#         )\n",
    "#         mnist_full = datasets.FashionMNIST(\n",
    "#             self.data_dir, train=True, download=True, transform=transforms.ToTensor()\n",
    "#         )\n",
    "#         self.mnist_train, self.mnist_val = random_split(mnist_full, [55000, 5000])\n",
    "\n",
    "#     def train_dataloader(self) -> DataLoader:\n",
    "#         return DataLoader(\n",
    "#             self.mnist_train, batch_size=self.batch_size, shuffle=True, pin_memory=True\n",
    "#         )\n",
    "\n",
    "#     def val_dataloader(self) -> DataLoader:\n",
    "#         return DataLoader(\n",
    "#             self.mnist_val, batch_size=self.batch_size, shuffle=False, pin_memory=True\n",
    "#         )\n",
    "\n",
    "#     def test_dataloader(self) -> DataLoader:\n",
    "#         return DataLoader(\n",
    "#             self.mnist_test, batch_size=self.batch_size, shuffle=False, pin_memory=True\n",
    "#         )\n",
    "\n",
    "\n",
    "# def objective(trial: optuna.trial.Trial) -> float:\n",
    "#     # We optimize the number of layers, hidden units in each layer and dropouts.\n",
    "#     n_layers = trial.suggest_int(\"n_layers\", 1, 3)\n",
    "#     dropout = trial.suggest_float(\"dropout\", 0.2, 0.5)\n",
    "#     output_dims = [\n",
    "#         trial.suggest_int(\"n_units_l{}\".format(i), 4, 128, log=True) for i in range(n_layers)\n",
    "#     ]\n",
    "\n",
    "#     model = LightningNet(dropout, output_dims)\n",
    "#     datamodule = FashionMNISTDataModule(data_dir=DIR, batch_size=BATCHSIZE)\n",
    "\n",
    "#     trainer = pl.Trainer(\n",
    "#         logger=True,\n",
    "#         limit_val_batches=PERCENT_VALID_EXAMPLES,\n",
    "#         enable_checkpointing=False,\n",
    "#         max_epochs=EPOCHS,\n",
    "#         accelerator=\"auto\",\n",
    "#         devices=1,\n",
    "#         callbacks=[PyTorchLightningPruningCallback(trial, monitor=\"val_acc\")],\n",
    "#     )\n",
    "#     hyperparameters = dict(n_layers=n_layers, dropout=dropout, output_dims=output_dims)\n",
    "#     trainer.logger.log_hyperparams(hyperparameters)\n",
    "#     trainer.fit(model, datamodule=datamodule)\n",
    "\n",
    "#     return trainer.callback_metrics[\"val_acc\"].item()\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "\n",
    "#     pruner = optuna.pruners.MedianPruner() \n",
    "\n",
    "#     study = optuna.create_study(direction=\"maximize\", pruner=pruner)\n",
    "#     study.optimize(objective, n_trials=100, timeout=600)\n",
    "\n",
    "#     print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
    "\n",
    "#     print(\"Best trial:\")\n",
    "#     trial = study.best_trial\n",
    "\n",
    "#     print(\"  Value: {}\".format(trial.value))\n",
    "\n",
    "#     print(\"  Params: \")\n",
    "#     for key, value in trial.params.items():\n",
    "#         print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# from pytorch_lightning import LightningModule\n",
    "# from pytorch_lightning import Trainer\n",
    "# from pytorch_lightning.callbacks import Callback\n",
    "# import optuna\n",
    "\n",
    "# class PyTorchLightningPruningCallback(Callback):\n",
    "#     \"\"\"PyTorch Lightning callback to prune unpromising trials.\n",
    "#     See `the example <https://github.com/optuna/optuna-examples/blob/\n",
    "#     main/pytorch/pytorch_lightning_simple.py>`__\n",
    "#     if you want to add a pruning callback which observes accuracy.\n",
    "#     Args:\n",
    "#         trial:\n",
    "#             A :class:`~optuna.trial.Trial` corresponding to the current evaluation of the\n",
    "#             objective function.\n",
    "#         monitor:\n",
    "#             An evaluation metric for pruning, e.g., ``val_loss`` or\n",
    "#             ``val_acc``. The metrics are obtained from the returned dictionaries from e.g.\n",
    "#             ``pytorch_lightning.LightningModule.training_step`` or\n",
    "#             ``pytorch_lightning.LightningModule.validation_epoch_end`` and the names thus depend on\n",
    "#             how this dictionary is formatted.\n",
    "#     \"\"\"\n",
    "\n",
    "#     def __init__(self, trial: optuna.trial.Trial, monitor: str) -> None:\n",
    "#         super().__init__()\n",
    "\n",
    "#         self._trial = trial\n",
    "#         self.monitor = monitor\n",
    "\n",
    "#     def on_validation_end(self, trainer: Trainer, pl_module: LightningModule) -> None:\n",
    "#         # When the trainer calls `on_validation_end` for sanity check,\n",
    "#         # do not call `trial.report` to avoid calling `trial.report` multiple times\n",
    "#         # at epoch 0. The related page is\n",
    "#         # https://github.com/PyTorchLightning/pytorch-lightning/issues/1391.\n",
    "#         if trainer.sanity_checking:\n",
    "#             return\n",
    "\n",
    "#         epoch = pl_module.current_epoch\n",
    "\n",
    "#         current_score = trainer.callback_metrics.get(self.monitor)\n",
    "#         if current_score is None:\n",
    "#             message = (\n",
    "#                 \"The metric '{}' is not in the evaluation logs for pruning. \"\n",
    "#                 \"Please make sure you set the correct metric name.\".format(self.monitor)\n",
    "#             )\n",
    "#             warnings.warn(message)\n",
    "#             return\n",
    "\n",
    "#         self._trial.report(current_score, step=epoch)\n",
    "#         if self._trial.should_prune():\n",
    "#             message = \"Trial was pruned at epoch {}.\".format(epoch)\n",
    "#             raise optuna.TrialPruned(message)\n",
    "#     def on_train_end(self, trainer, pl_module):\n",
    "#         print(pl_module.current_epoch)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 4647668,
     "sourceId": 8287015,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30673,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
